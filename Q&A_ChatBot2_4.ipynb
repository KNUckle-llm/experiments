{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KNUckle-llm/experiments/blob/main/Q%26A_ChatBot2_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEER2kRiIwvS"
      },
      "outputs": [],
      "source": [
        "# 인공지능 PDF Q&A 챗봇 프로젝트 2-4\n",
        "# 추가점 1 : Goole Vision 사용해서 pdf인데 사진으로 된 것들 저장하기(완)\n",
        "# 추가점 2 : 각 부서별에 해당하는 벡터 DB를 가져와 retriever로 검색하는 방식, 선택 안하면 모든 부서 정보가 들어간 DB를 가져와 검색(완)\n",
        "# 추가점 3 : 각 부서별로 프롬프트 메시지 다른거 사용하기(미완)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "s1WwBRU_Nq9y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5KCM5kP6No8S"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3R-NCn3dOPWk"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_openai==0.3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-Mw_Wf-zPhtF"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-huggingface==0.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hF1lOXXOPkQX"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community==0.3.18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DW2y0rt0Rjjv"
      },
      "outputs": [],
      "source": [
        "#!pip install faiss-cpu==1.10.0\n",
        "!pip install langchain_chroma==0.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "D5quX3Ac8eVU"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RG_3magVch41"
      },
      "outputs": [],
      "source": [
        "#!pip install pydantic==2.10.6\n",
        "#!pip uninstall -y gradio\n",
        "#!pip install --upgrade gradio gradio-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qXZuuZ05P3qO"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall numpy -y\n",
        "#!pip install --no-cache-dir numpy==1.26.4\n",
        "# colab에 numpy 2.버전이 설치되어 있어서 버전 충돌남"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqCQ32ozSclI",
        "outputId": "e7d7c9cb-a737-4e6b-e563-89a55a582df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "print(numpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObqvRExvFmXG",
        "outputId": "436ddcd0-e3dd-45ad-8ac1-8599866e5431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.31.0\n"
          ]
        }
      ],
      "source": [
        "import gradio\n",
        "print(gradio.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MXM0w5Q5t0c"
      },
      "outputs": [],
      "source": [
        "%pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-vision pdf2image\n",
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "id": "Pb1yms9cVH0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krtuPwiOIwfj"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import uuid\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, trim_messages\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain_core.documents import Document\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "# 환경 변수 불러오기(openai API 키)\n",
        "load_dotenv('/content/drive/MyDrive/Colab Notebooks/.env')\n",
        "\n",
        "# LLM 설정\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# 텍스트 분리\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n",
        "# 임베딩 모델\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
        "\n",
        "# 프롬프트 템플릿\n",
        "system_message = \"\"\"\n",
        "당신은 공주대학교와 관련된 정보를 안내하는 AI입니다.\n",
        "공식 문서나 공주대학교 사이트에서 제공되는 정보만 바탕으로 대답하세요.\n",
        "문맥에서 명확한 정보가 없으면 \"찾을 수 없습니다\"라고 말해주세요.\n",
        "정확한 출처를 아래와 같이 반드시 포함하세요.\n",
        "파일명 :\n",
        "부서/학과 :\n",
        "URL :\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message),\n",
        "        (\"placeholder\", \"{memory}\"),\n",
        "        (\"user\", \"🔍 검색된 문서:\\n{context}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 출력 파서\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# 트리머 설정\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=500,\n",
        "    token_counter=llm,\n",
        "    strategy=\"last\",\n",
        "    include_system=True,\n",
        "    start_on=\"human\"\n",
        ")\n",
        "\n",
        "DEPARTMENT_MAP = {\n",
        "    \"ALL(전체)\" : \"knu_chroma_db_all\",\n",
        "    \"Software Department (소프트웨어학과)\": \"knu_chroma_db_software\",\n",
        "    \"Department of Computer Engineering (컴퓨터공학과)\": \"knu_chroma_db_computer\",\n",
        "    #\"동아리\": \"knu_chroma_db_club\",\n",
        "    #\"대학원\": \"knu_chroma_db_gradschool\",\n",
        "    #\"소프트웨어중심대학사업단\": \"knu_chroma_db_center\"\n",
        "}\n",
        "\n",
        "# 전역\n",
        "retriever = None\n",
        "rag_chain = None\n",
        "history_store: dict[str, InMemoryChatMessageHistory] = {}\n",
        "\n",
        "# 세션 초기화 함수\n",
        "def init_session(session_id: str):\n",
        "    if not session_id or not isinstance(session_id, str):\n",
        "        raise ValueError(\"유효한 session_id가 필요합니다.\")\n",
        "\n",
        "    if session_id not in history_store:\n",
        "        history_store[session_id] = InMemoryChatMessageHistory()\n",
        "\n",
        "    # SystemMessage가 이미 포함되어 있는지 확인\n",
        "    existing = history_store[session_id].messages\n",
        "    if not any(msg.type == \"system\" and msg.content.strip() == system_message.strip() for msg in existing):\n",
        "        history_store[session_id].add_message(SystemMessage(content=system_message.strip()))\n",
        "\n",
        "# 세션 히스토리 함수\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    return history_store[session_id]\n",
        "\n",
        "def load_all_docs_once():\n",
        "    global all_docs\n",
        "    if not all_docs:\n",
        "        for dept, dir_name in DEPARTMENT_MAP.items():\n",
        "            db = Chroma(persist_directory=f\"/content/drive/MyDrive/ChromaDB/{dir_name}\", embedding_function=hf_embeddings)\n",
        "            res = db.get(include=[\"documents\", \"metadatas\"])\n",
        "            all_docs.extend([Document(page_content=d, metadata=m) for d, m in zip(res[\"documents\"], res[\"metadatas\"])])\n",
        "\n",
        "# RAG 체인 로드\n",
        "def rebuild_chain(selected_dept: str = None):\n",
        "    global retriever, rag_chain\n",
        "\n",
        "    # 사용자가 부서를 선택한 경우: 해당 부서 전용 DB만 불러와 retriever 구성(빠름)\n",
        "    if selected_dept:\n",
        "        db_path = f\"/content/drive/MyDrive/ChromaDB/{DEPARTMENT_MAP[selected_dept]}\"\n",
        "        db = Chroma(persist_directory=db_path, embedding_function=hf_embeddings)\n",
        "    else:\n",
        "        # 부서를 선택하지 않은 경우: 모든 부서의 문서가 저장된 DB를 로드하여 retriever 구성(느림)\n",
        "        db_path = f\"/content/drive/MyDrive/ChromaDB/knu_chroma_db_all\"\n",
        "        db = Chroma(persist_directory=db_path, embedding_function=hf_embeddings)\n",
        "\n",
        "    \"\"\"\n",
        "    벡터 거리 기반 의미 검색\n",
        "    질문 -> MultiQuery(3개의 서브 질문)\n",
        "    서브 질문 1 -> ChromaDB에서 mmr방식(다양하고도 유사한 문서를 찾는 방식)으로 검색하여 10개 후보 중 5개를 선택\n",
        "    서브 질문 2 -> ChromaDB에서 mmr방식으로 검색하여 10개 후보 중 5개를 선택\n",
        "    서브 질문 3 -> ChromaDB에서 mmr방식으로 검색하여 10개 후보 중 5개를 선택\n",
        "    -> 전체 15개 청크 검색됨 -> 중복 제거 -> 고유 청크 N개(15개 이하)\n",
        "\n",
        "    키워드 기반 재정렬 - Document 리스트 상태에서 작동함\n",
        "    청크 N개를 대상으로 BM25(키워드(=질문에서 나온 단어)가 문서 안에 얼마나 잘 등장하는지 관련성을 수치화하는 방식)\n",
        "    -> top 3개 선택\n",
        "    -> LLM context에 top3 청크 3개 삽입 -> 답변 생성\n",
        "    \"\"\"\n",
        "    # 전체 문서 로딩 후 BM25 구성용 문서 리스트 확보\n",
        "    results = db.get(include=[\"documents\", \"metadatas\"])\n",
        "    docs = [Document(page_content=doc, metadata=meta) for doc, meta in zip(results[\"documents\"], results[\"metadatas\"])]\n",
        "\n",
        "    # Chroma + BM25 혼합 검색기 구성\n",
        "    chroma_retriever = db.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\"k\": 3, \"fetch_k\": 10, \"lambda_mult\": 0.5}\n",
        "    )\n",
        "\n",
        "    bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "    bm25_retriever.k = 3\n",
        "    base_retriever = EnsembleRetriever(retrievers=[chroma_retriever, bm25_retriever])\n",
        "    retriever = MultiQueryRetriever.from_llm(base_retriever, llm=llm)\n",
        "\n",
        "    # 최종 RAG 체인\n",
        "    rag_chain_core = {\n",
        "        \"memory\": trimmer,      # trimmer 적용\n",
        "        \"context\": retriever,\n",
        "        \"input\": RunnablePassthrough()\n",
        "    } | prompt_template | llm | parser\n",
        "\n",
        "    # 최종 RAG 체인\n",
        "    rag_chain = RunnableWithMessageHistory(\n",
        "        rag_chain_core,\n",
        "        get_session_history,\n",
        "        input_messages_key=\"input\",\n",
        "        history_messages_key=\"memory\"\n",
        "    )\n",
        "\n",
        "# 질문 처리\n",
        "def answer_question(question: str, session_id: str) -> str:\n",
        "    if not session_id:\n",
        "        return \"⚠️ 세션을 먼저 생성하거나 선택해주세요.\"\n",
        "\n",
        "    init_session(session_id)\n",
        "\n",
        "    # rag_chain의 입력 형식에 맞춰 dict 구성\n",
        "    chain_input = {\n",
        "        \"memory\": None,        # RunnableWithMessageHistory가 알아서 처리\n",
        "        \"context\": None,       # retriever가 알아서 처리\n",
        "        \"input\": question\n",
        "    }\n",
        "\n",
        "    # RAG 체인 호출 → 답변 생성(자동으로 history에 기록됨)\n",
        "    answer = rag_chain.invoke(\n",
        "        chain_input,\n",
        "        config={\"configurable\": {\"session_id\": session_id}}\n",
        "    )\n",
        "    return answer\n",
        "\n",
        "# 여러개의 Chroma DB에 저장된 문서 목록 보여주는 함수 -> 애도 안씀\n",
        "def show_stored_documents():\n",
        "    file_names = set()\n",
        "\n",
        "    try:\n",
        "        for dept, dir_name in DEPARTMENT_MAP.items():\n",
        "            db = Chroma(\n",
        "                persist_directory=f\"/content/drive/MyDrive/ChromaDB/{dir_name}\",\n",
        "                embedding_function=hf_embeddings\n",
        "            )\n",
        "            result = db.get(include=[\"metadatas\"])\n",
        "            metas = result.get(\"metadatas\", [])\n",
        "            for meta in metas:\n",
        "                file_name = meta.get(\"file_name\", \"Unknown\")\n",
        "                department = meta.get(\"department\", dept)\n",
        "                file_names.add(f\"{file_name} ({department})\")\n",
        "    except Exception as e:\n",
        "        return f\"❗ DB에서 메타데이터 로드 중 오류 발생: {e}\"\n",
        "\n",
        "    if not file_names:\n",
        "        return \"📂 문서가 없습니다.\"\n",
        "\n",
        "    return \"📚 저장된 문서 목록:\\n\" + \"\\n\".join(f\"• {f}\" for f in sorted(file_names))\n",
        "\n",
        "# 세션별로 저장된 대화 내역 보여주는 함수(Human/AI)\n",
        "def show_history(session_id: str) -> str:\n",
        "    init_session(session_id)\n",
        "    msgs = get_session_history(session_id).messages\n",
        "\n",
        "    if not msgs:\n",
        "        return \"⚠️ 대화 기록이 없습니다.\"\n",
        "\n",
        "    output = []\n",
        "    for msg in msgs:\n",
        "        if msg.type == \"system\":\n",
        "            output.append(f\"📘 System: {msg.content.strip()}\")\n",
        "        elif msg.type == \"human\":\n",
        "            output.append(f\"🧑 Human: {msg.content.strip()}\")\n",
        "        elif msg.type == \"ai\":\n",
        "            output.append(f\"🤖 AI: {msg.content.strip()}\")\n",
        "    return \"\\n\\n\".join(output)\n",
        "\n",
        "# Gradio UI 설정\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    # ── 사이드바: 세션 관리 ──\n",
        "    with gr.Sidebar():\n",
        "        session_dropdown = gr.Dropdown(\n",
        "            label=\"채팅 세션 선택\",\n",
        "            choices=[],\n",
        "            value=None,\n",
        "            interactive=True\n",
        "        )\n",
        "        new_session_btn = gr.Button(\"➕ 새 채팅\")\n",
        "        del_session_btn = gr.Button(\"🗑 세션 삭제\")\n",
        "\n",
        "        department_dropdown = gr.Dropdown(\n",
        "            label=\"🔍 검색할 부서/학과 선택\",\n",
        "            choices=list(DEPARTMENT_MAP.keys()),\n",
        "            value=None,\n",
        "            interactive=True\n",
        "        )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 📄 인공지능 PDF Q&A 챗봇\n",
        "    **여러 PDF 파일을 업로드하고 질문을 입력하면 AI가 답변을 제공합니다!**\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            show_files_button = gr.Button(\"📚 저장된 문서 보기\")\n",
        "            status_output = gr.Textbox(label=\"📢 상태 메시지\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            question_input = gr.Textbox(label=\"❓ 질문 입력\", placeholder=\"궁금한 내용을 적어주세요.\")\n",
        "            submit_button = gr.Button(\"🤖 답변 받기\")\n",
        "            answer_output = gr.Textbox(label=\"📝 AI 답변\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            show_history_button = gr.Button(\"🕘 히스토리 보기\")\n",
        "            history_output = gr.Textbox(label=\"🗒 전체 대화 내역 | System/Human/AI Message\", lines=15, interactive=False)\n",
        "\n",
        "    # ── 사이드바 이벤트 바인딩 ──\n",
        "    def create_session():\n",
        "        sid = f\"session_{uuid.uuid4().hex[:8]}\"\n",
        "        init_session(sid)\n",
        "        return gr.update(choices=list(history_store.keys()), value=sid)\n",
        "\n",
        "    # 세션 삭제 함수\n",
        "    def delete_session(session_id: str):\n",
        "        history_store.pop(session_id, None)\n",
        "\n",
        "    new_session_btn.click(\n",
        "        fn=create_session,\n",
        "        inputs=None,\n",
        "        outputs=[session_dropdown]\n",
        "    )\n",
        "\n",
        "    def remove_session(sid):\n",
        "        delete_session(sid)\n",
        "        keys = list(history_store.keys())\n",
        "        new_val = keys[0] if keys else None\n",
        "        return gr.update(choices=keys, value=new_val)\n",
        "\n",
        "    del_session_btn.click(\n",
        "        fn=remove_session,\n",
        "        inputs=[session_dropdown],\n",
        "        outputs=[session_dropdown]\n",
        "    )\n",
        "    session_dropdown.choices = list(history_store.keys())\n",
        "\n",
        "    # ── 부서 선택 시 RAG 체인 재구성 이벤트 바인딩 ──\n",
        "    def on_department_selected(dept_name):\n",
        "        rebuild_chain(dept_name)\n",
        "        return f\"✅ '{dept_name}' 부서 기준으로 검색기를 재설정했습니다.\"\n",
        "\n",
        "    department_dropdown.change(\n",
        "        fn=on_department_selected,\n",
        "        inputs=[department_dropdown],\n",
        "        outputs=[status_output]\n",
        "    )\n",
        "\n",
        "    # ── 파일 업로드 / 질문 / 히스토리 이벤트 ──\n",
        "    submit_button.click(answer_question, inputs=[question_input, session_dropdown], outputs=answer_output)\n",
        "    show_files_button.click(show_stored_documents, outputs=status_output)\n",
        "    show_history_button.click(show_history, inputs=[session_dropdown], outputs=history_output)\n",
        "\n",
        "# 벡터 DB 로드 후 실행\n",
        "rebuild_chain()\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7YUqoagH4Vr"
      },
      "outputs": [],
      "source": [
        "# 드라이브 내 폴더 안에 존재하는 pdf 파일들 저장하는 코드\n",
        "# 흐름: 폴더 순회 -> pdf/md 파일 1개 찾기 → URL 매칭(유사도 기반) : 파일명을 가지고 URL 알아오기 -> 텍스트 load & split(청킹) → 메타 정보 추가 -> ChromaDB에 저장(자동 임베딩)\n",
        "# 흐름을 반복하여 처리하는 파이프라인\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import logging\n",
        "import warnings\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "from difflib import SequenceMatcher\n",
        "from io import BytesIO\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "# from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "from google.cloud import vision\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "# === Google Vision API 설정 === #\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drive/MyDrive/Colab Notebooks/lively-sentry-460812-j2-b70abbe49963.json\"\n",
        "vision_client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# — 설정 — #\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Cheonan Campus All Departments (천안캠퍼스 모든 학과)/Department of Computer Engineering (컴퓨터공학과)\"   # 순회할 최상위 폴더\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/ChromaDB/knu_chroma_db_computer\"         # ChromaDB 저장 디렉토리\n",
        "EMB_MODEL     = \"BAAI/bge-m3\"\n",
        "URL_XLSX_PATH = os.path.join(ROOT_FOLDER, \"Computer Department (컴퓨터공학과)_url.xlsx\")\n",
        "SIMILARITY_CUTOFF = 0.7\n",
        "\n",
        "# PyPDF 경고 무시\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "logging.getLogger(\"pypdf\").setLevel(logging.ERROR)\n",
        "\n",
        "# — 로깅 설정 (Colab에서도 보이게) — #\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "handler.setFormatter(formatter)\n",
        "if not logger.hasHandlers():\n",
        "    logger.addHandler(handler)\n",
        "\n",
        "# 파일명 정규화: NFC → 확장자 제거 → 공백 제거\n",
        "def normalize_name(name: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFC\", name)\n",
        "    s = re.sub(r\"\\.\\w+$\", \"\", s)  # .pdf, .md 등 제거\n",
        "    return s.replace(\" \", \"\")\n",
        "\n",
        "# 1) URL 매핑 로드\n",
        "def load_url_map(path: str) -> dict:\n",
        "    df = pd.read_excel(path)\n",
        "    return {\n",
        "        normalize_name(str(fn)): url\n",
        "        for fn, url in zip(df[\"파일명\"], df[\"URL\"])\n",
        "    }\n",
        "URL_MAP = load_url_map(URL_XLSX_PATH)\n",
        "\n",
        "# 2) 가장 유사한 URL 찾아주는 함수\n",
        "def find_best_url(base_norm: str, url_map: dict, cutoff: float) -> str:\n",
        "    # 완전 일치\n",
        "    if base_norm in url_map:\n",
        "        logger.info(f\"🔗 URL 100% 일치: '{base_norm}' → {url_map[base_norm]}\")\n",
        "        return url_map[base_norm]\n",
        "\n",
        "    # 유사도 탐색\n",
        "    best_key, best_score = None, 0.0\n",
        "    for key in url_map:\n",
        "        score = SequenceMatcher(None, base_norm, key).ratio()\n",
        "        if score > best_score:\n",
        "            best_key, best_score = key, score\n",
        "\n",
        "    if best_score >= cutoff:\n",
        "        logger.info(f\"🔍 유사도({best_score:.2f}) 매칭: '{base_norm}' → '{best_key}' → {url_map[best_key]}\")\n",
        "        return url_map[best_key]\n",
        "    else:\n",
        "        logger.info(f\"❌ URL 매칭 실패({best_score:.2f}): '{base_norm}' → URL 없음\")\n",
        "        return \"\"\n",
        "\n",
        "# 3) Loader 선택 (.pdf/.md)\n",
        "def get_loader(fp: Path):\n",
        "    ext = fp.suffix.lower()\n",
        "    if ext == \".pdf\":\n",
        "        return PyPDFLoader(str(fp))\n",
        "    if ext == \".md\":\n",
        "        return TextLoader(str(fp), encoding=\"utf-8\")\n",
        "    return None\n",
        "\n",
        "# OCR 처리 함수\n",
        "def ocr_pdf_to_text(pdf_path: str) -> str:\n",
        "    text_list = []\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        for i, image in enumerate(images):\n",
        "            img_byte_arr = BytesIO()\n",
        "            image.save(img_byte_arr, format='JPEG')\n",
        "            content = img_byte_arr.getvalue()\n",
        "            image_vision = vision.Image(content=content)\n",
        "            response = vision_client.document_text_detection(image=image_vision)\n",
        "            text = response.full_text_annotation.text\n",
        "            logger.info(f\"📝 OCR 추출 (p.{i+1}): {len(text)}자\")\n",
        "            text_list.append(text)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ OCR 처리 실패: {e}\")\n",
        "    return \"\\n\".join(text_list)\n",
        "\n",
        "# 4) Splitter & Embedding 준비\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        ")\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL)\n",
        "\n",
        "# 5) ChromaDB 로드 (폴더가 없으면 내부적으로 새로 생성됨)\n",
        "db = Chroma(\n",
        "    persist_directory=PERSIST_DIR,\n",
        "    embedding_function=hf_embeddings\n",
        ")\n",
        "logger.info(\"🔄 ChromaDB 로드/초기화 완료\")\n",
        "\n",
        "# 6) 파일 순회하며 청킹 + 메타 추가 + DB 저장\n",
        "for fp in Path(ROOT_FOLDER).rglob(\"*.*\"):\n",
        "    loader = get_loader(fp)\n",
        "    if loader is None:\n",
        "        continue\n",
        "\n",
        "    base_raw  = fp.name\n",
        "    base_norm = normalize_name(base_raw)\n",
        "    # department 추출 (현재 루트 폴더 기준)\n",
        "    department = Path(ROOT_FOLDER).name\n",
        "\n",
        "    # 중복 체크: file_name과 department가 모두 일치할 경우에만 중복 간주\n",
        "    try:\n",
        "        results = db.get(where={\"file_name\": {\"$eq\": base_raw}})\n",
        "        metadatas = results.get(\"metadatas\", [])\n",
        "        if any(md.get(\"department\") == department for md in metadatas):\n",
        "            logger.info(f\"⏭️ 이미 저장된 파일: {base_raw} ({department}) → 스킵\")\n",
        "            continue\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"❗ 중복 검사 실패 (무시하고 진행): {e}\")\n",
        "\n",
        "    logger.info(f\"📄 파일 로드 & 청킹 시작: {fp.relative_to(ROOT_FOLDER)}\")\n",
        "    url = find_best_url(base_norm, URL_MAP, SIMILARITY_CUTOFF)\n",
        "\n",
        "    # 로드 & 청킹\n",
        "    try:\n",
        "        chunks = loader.load_and_split(text_splitter=text_splitter)\n",
        "        logger.info(f\"🧩 청크 생성: {len(chunks)}개\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ '{base_raw}' 로드/청킹 실패: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 청크가 0개면 사진으로된 pdf문서이므로 OCR 시도\n",
        "    if not chunks and fp.suffix.lower() == \".pdf\":\n",
        "        logger.warning(f\"⚠️ '{base_raw}' 빈 청크 → 사진으로 된 pdf\")\n",
        "        logger.info(f\"🖼️ OCR 처리 시도: {base_raw}\")\n",
        "        ocr_text = ocr_pdf_to_text(str(fp))\n",
        "        if ocr_text.strip():\n",
        "            chunks = text_splitter.create_documents([ocr_text])\n",
        "        else:\n",
        "            logger.warning(f\"⚠️ OCR 실패 또는 빈 결과: {base_raw}\")\n",
        "            continue\n",
        "\n",
        "    # 메타 추가\n",
        "    for chunk in chunks:\n",
        "        chunk.metadata.update({\n",
        "            \"file_name\":  base_raw,\n",
        "            \"department\": department,\n",
        "            \"url\":        url\n",
        "        })\n",
        "\n",
        "    # DB 저장\n",
        "    db.add_documents(chunks)\n",
        "    logger.info(f\"➕ '{base_raw}' — {len(chunks)}개 Chroma DB에 저장 완료\")\n",
        "\n",
        "logger.info(\"🎉 모든 파일 처리 완료 — ChromaDB에 반영되었습니다\")\n",
        "count = db._collection.count()\n",
        "logger.info(f\"현재 DB 청크화된 문서 개수: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQW_Hdd07pWS"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# — 설정 — #\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/ChromaDB/knu_chroma_db_computer\"\n",
        "EMB_MODEL   = \"BAAI/bge-m3\"\n",
        "\n",
        "# 1) DB 로드\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL)\n",
        "db = Chroma(persist_directory=PERSIST_DIR, embedding_function=hf_embeddings)\n",
        "\n",
        "# 2) 메타정보만 꺼내오기\n",
        "res = db.get(include=[\"metadatas\"])\n",
        "\n",
        "# 3) 총 청크 수 및 파일명·부서·URL 출력\n",
        "metas = res[\"metadatas\"]\n",
        "print(f\"총 청크 수: {len(metas)}\\n\")\n",
        "for meta in metas:\n",
        "    print(\n",
        "        f\"파일명: {meta.get('file_name','Unknown')}  |  \"\n",
        "        f\"부서: {meta.get('department','Unknown')}  |  \"\n",
        "        f\"URL: {meta.get('url','')}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ-uYzmm_4XX",
        "outputId": "36f2a5c0-d506-462e-f066-eed3478baac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🗑️ '/content/drive/MyDrive/ChromaDB/knu_chroma_db_computer' 폴더를 완전히 제거했습니다.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "import shutil\n",
        "\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/ChromaDB/knu_chroma_db_computer\"\n",
        "\n",
        "# 1) 폴더 자체를 날려버리기\n",
        "shutil.rmtree(PERSIST_DIR)\n",
        "\n",
        "print(f\"🗑️ '{PERSIST_DIR}' 폴더를 완전히 제거했습니다.\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sze8a2wqUg8m"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/ChromaDB/knu_chroma_db\"\n",
        "EMB_MODEL   = \"BAAI/bge-m3\"\n",
        "\n",
        "# DB 로드\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL)\n",
        "db = Chroma(persist_directory=PERSIST_DIR, embedding_function=hf_embeddings)\n",
        "\n",
        "# 1. where 절로 메타데이터 필터링\n",
        "try:\n",
        "    results = db.get(\n",
        "        where={\"department\": {\"$eq\": \"Department of Computer Engineering (컴퓨터공학과)\"}},\n",
        "        include=[\"metadatas\", \"documents\"]  # include에 ids는 쓰면 안 됨\n",
        "    )\n",
        "    ids_to_delete = results[\"ids\"]  # 여기서 id가 자동 포함됨\n",
        "\n",
        "    if ids_to_delete:\n",
        "        db.delete(ids=ids_to_delete)\n",
        "        print(f\"🗑️ 삭제된 청크 수: {len(ids_to_delete)}\")\n",
        "    else:\n",
        "        print(\"✅ 삭제할 청크가 없습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"❗ 삭제 중 오류 발생: {e}\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" OCR 사용 방법 예제\n",
        "from google.colab import drive\n",
        "import os\n",
        "from google.cloud import vision\n",
        "from pdf2image import convert_from_path\n",
        "from io import BytesIO\n",
        "\n",
        "# 서비스 계정 키 경로\n",
        "# 구글 비전 OCR api 키\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drive/MyDrive/Colab Notebooks/lively-sentry-460812-j2-b70abbe49963.json\"\n",
        "\n",
        "# Vision API 클라이언트 생성\n",
        "vision_client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# OCR 대상 PDF 경로\n",
        "pdf_path = \"/content/drive/MyDrive/Cheonan Campus All Departments (천안캠퍼스 모든 학과)/Software Department (소프트웨어학과)/커뮤니티 (특강공지)/보물의 세계 이벤트.pdf\"\n",
        "\n",
        "# PDF → 이미지로 변환\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "# 🚗 6. OCR 처리\n",
        "for i, image in enumerate(images):\n",
        "    img_byte_arr = BytesIO()\n",
        "    image.save(img_byte_arr, format='JPEG')\n",
        "    content = img_byte_arr.getvalue()\n",
        "\n",
        "    image_vision = vision.Image(content=content)\n",
        "    response = vision_client.document_text_detection(image=image_vision)\n",
        "    text = response.full_text_annotation.text\n",
        "    print(f\"📝 [페이지 {i+1}] OCR 결과:\")\n",
        "    print(text)\n",
        "    print(\"-\" * 50)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IGM-u2-qU6X6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOd9j+BkfIDFHnEsw42ipeq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}