{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyM2cTTjLzNmTe7ANAfP5M54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KNUckle-llm/experiments/blob/main/Q%26A_ChatBot2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEER2kRiIwvS"
      },
      "outputs": [],
      "source": [
        "# ì¸ê³µì§€ëŠ¥ PDF Q&A ì±—ë´‡ í”„ë¡œì íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s1WwBRU_Nq9y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5KCM5kP6No8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai==0.3.7"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3R-NCn3dOPWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface==0.1.2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-Mw_Wf-zPhtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community==0.3.18"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hF1lOXXOPkQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install faiss-cpu==1.10.0\n",
        "!pip install langchain_chroma==0.2.2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DW2y0rt0Rjjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D5quX3Ac8eVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pydantic==2.10.6\n",
        "#!pip uninstall -y gradio\n",
        "#!pip install --upgrade gradio gradio-client"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RG_3magVch41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall numpy -y\n",
        "#!pip install --no-cache-dir numpy==1.26.4\n",
        "# colabì— numpy 2.ë²„ì „ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì„œ ë²„ì „ ì¶©ëŒë‚¨"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qXZuuZ05P3qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(numpy.__version__)"
      ],
      "metadata": {
        "id": "SqCQ32ozSclI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d84d6e-f015-43f9-fab4-04c1eb3a498b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio\n",
        "print(gradio.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObqvRExvFmXG",
        "outputId": "b4f33caf-196d-4f37-9c16-cd8d2ca5bbb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "#from langchain_community.vectorstores import FAISS\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, trim_messages\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°(openai API í‚¤)\n",
        "load_dotenv('/content/drive/MyDrive/Colab Notebooks/.env')\n",
        "\n",
        "# LLM ì„¤ì •\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ë¶„ë¦¬\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "system_message = \"\"\"\n",
        "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
        "ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥ì„ í† ëŒ€ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
        "ë§Œì•½, ë¬¸ë§¥ì—ì„œ ë‹µë³€ì„ ìœ„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ 'ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' ë¼ê³  ë‹µí•˜ì„¸ìš”.\n",
        "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´ í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "human_message = \"\"\"\n",
        "## ê³¼ê±° ëŒ€í™” ë‚´ì—­:\n",
        "{memory}\n",
        "\n",
        "## ê²€ìƒ‰ëœ ë¬¸ì„œ:\n",
        "{context}\n",
        "\n",
        "## ìµœì‹  ì‚¬ìš©ì ì§ˆë¬¸:\n",
        "{input}\n",
        "\"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", human_message)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ì¶œë ¥ íŒŒì„œ\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# íŠ¸ë¦¬ë¨¸ ì„¤ì •\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=200,\n",
        "    token_counter=llm,\n",
        "    strategy=\"last\",\n",
        "    include_system=False,\n",
        "    start_on=\"human\"\n",
        ")\n",
        "\n",
        "# ì „ì—­ ë³€ìˆ˜\n",
        "db = None\n",
        "retriever = None\n",
        "rag_chain = None\n",
        "#faiss_path = \"/content/drive/MyDrive/FaissDB/knu_faiss_db\"\n",
        "chroma_path = \"/content/drive/MyDrive/ChromaDB/knu_chroma_db\"\n",
        "history_store: dict[str, InMemoryChatMessageHistory] = {}\n",
        "session_counter = 1\n",
        "\n",
        "# ì„¸ì…˜ ì´ˆê¸°í™” í•¨ìˆ˜\n",
        "def init_session(session_id: str):\n",
        "    if session_id in history_store:\n",
        "        return\n",
        "    messages = InMemoryChatMessageHistory()\n",
        "    messages.add_message(SystemMessage(content=system_message))\n",
        "    history_store[session_id] = messages\n",
        "\n",
        "# ì„¸ì…˜ íˆìŠ¤í† ë¦¬ í•¨ìˆ˜, ìµœê·¼ 3ìŒì˜ Q&A ë©”ì‹œì§€ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ(ì†ë„ ì¦ê°€)\n",
        "def get_session_history(session_id: str, limit: int = 6) -> BaseChatMessageHistory:\n",
        "    messages = history_store[session_id]\n",
        "    while len(messages.messages) > limit + 1:\n",
        "        del messages.messages[1]\n",
        "    return messages\n",
        "\n",
        "# RAG ì²´ì¸ ë¡œë“œ\n",
        "def load_chain():\n",
        "    global retriever, rag_chain\n",
        "\n",
        "    # ê²€ìƒ‰ê¸° context\n",
        "    base_retriever = db.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\"k\": 3, \"fetch_k\": 10, \"lambda_mult\": 0.5}\n",
        "    )\n",
        "    # LLMì„ ì´ìš©í•´ ì—¬ëŸ¬ ê°œì˜ ì„œë¸Œ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ base_retrieverì— ë„˜ê²¨ ë” í’ë¶€í•œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´(ê¸°ë³¸: 3)\n",
        "    retriever = MultiQueryRetriever.from_llm(base_retriever, llm = llm)\n",
        "\n",
        "    # ëŒ€í™” ë‚´ì—­ ë¶ˆëŸ¬ì™€ì„œ trimmer ì ìš©\n",
        "    history = RunnableWithMessageHistory(RunnablePassthrough(), get_session_history)\n",
        "    trimmed = history | trimmer\n",
        "\n",
        "    # ìµœì¢… RAG ì²´ì¸\n",
        "    rag_chain = {\n",
        "        \"memory\" : trimmed,\n",
        "        \"context\": retriever,\n",
        "        \"input\": RunnablePassthrough()\n",
        "    } | prompt_template | llm | parser\n",
        "\n",
        "\"\"\"\n",
        "# FAISS DB ë¡œë“œ\n",
        "def load_faiss_db():\n",
        "    global db\n",
        "    db = FAISS.load_local(\n",
        "        folder_path=faiss_path,\n",
        "        embeddings=hf_embeddings,\n",
        "        allow_dangerous_deserialization=True\n",
        "    )\n",
        "\"\"\"\n",
        "\n",
        "# Chroma DB ë¡œë“œ\n",
        "def load_chroma_db():\n",
        "    global db\n",
        "    db = Chroma(persist_directory=chroma_path, embedding_function=hf_embeddings)\n",
        "    load_chain()\n",
        "\n",
        "# PDF ì—…ë¡œë“œ ë° DB ì €ì¥\n",
        "def add_pdf_to_db(file):\n",
        "    global db\n",
        "\n",
        "    loader = PyPDFLoader(file.name)\n",
        "    docs = loader.load_and_split(text_splitter=text_splitter)\n",
        "\n",
        "    # ê° ì²­í¬ì— íŒŒì¼ëª… metadata ì¶”ê°€\n",
        "    for doc in docs:\n",
        "        doc.metadata[\"file_name\"] = os.path.basename(file.name)\n",
        "        # ë©”íƒ€ë°ì´í„° ì¶”ê°€ ê°€ëŠ¥\n",
        "\n",
        "    if db is None:\n",
        "        # db = FAISS.from_documents(docs, hf_embeddings)\n",
        "        db = Chroma.from_documents(docs, embedding_function=hf_embeddings, persist_directory=chroma_path)\n",
        "    else:\n",
        "      db.add_documents(docs)\n",
        "\n",
        "    # db.save_local(faiss_path)\n",
        "    load_chain()    # DBê°€ ë°”ë€Œì—ˆìœ¼ë‹ˆ retriever/chainì„ ì—…ë°ì´íŠ¸\n",
        "    return f\"{os.path.basename(file.name)} ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì—¬ ChromaDBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "# ì§ˆë¬¸ ì²˜ë¦¬\n",
        "def answer_question(question: str, session_id: str) -> str:\n",
        "    init_session(session_id)\n",
        "    # RAG ì²´ì¸ í˜¸ì¶œ â†’ ë‹µë³€ ìƒì„±(ìë™ìœ¼ë¡œ historyì— ê¸°ë¡ë¨)\n",
        "    answer = rag_chain.invoke(\n",
        "        question,\n",
        "        config={\"configurable\": {\"session_id\": session_id}}\n",
        "    )\n",
        "    # AI ë©”ì‹œì§€ ìˆ˜ë™ ì €ì¥\n",
        "    get_session_history(session_id).add_message(AIMessage(content=answer))\n",
        "    return answer\n",
        "\n",
        "# FAISS DBì— ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜\n",
        "def show_stored_documents():\n",
        "    if db is None:\n",
        "        return \"DB ë¡œë“œ ë¬¸ì œ\"\n",
        "    #docs = list(db.docstore._dict.values())  # ì €ì¥ëœ ëª¨ë“  ì²­í¬ë“¤ì„ ê°€ì ¸ì™€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
        "    #file_names = {doc.metadata.get(\"file_name\", \"Unknown\") for doc in docs}\n",
        "    result = db.get(include=[\"metadatas\"])\n",
        "    metas = result.get(\"metadatas\", [])\n",
        "    file_names = {meta.get(\"file_name\", \"Unknown\") for meta in metas}\n",
        "    return \"ğŸ“š ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡:\\n\" + \"\\n\".join(f\"â€¢ {f}\" for f in sorted(file_names))\n",
        "\n",
        "# ì„¸ì…˜ë³„ë¡œ ì €ì¥ëœ ëŒ€í™” ë‚´ì—­ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜(Human/AI)\n",
        "def show_history(session_id: str) -> str:\n",
        "    init_session(session_id)\n",
        "    msgs = get_session_history(session_id).messages\n",
        "\n",
        "    lines = []\n",
        "    if msgs and msgs[0].type == \"system\":\n",
        "        lines.append(f\"System: {msgs[0].content.strip()}\")\n",
        "\n",
        "    seq = [(m.type, m.content.strip()) for m in msgs if m.type in (\"human\", \"ai\")]\n",
        "    pairs = [\n",
        "        f\"Human: {usr}\\nAI: {ai}\"\n",
        "        for (t1, usr), (t2, ai) in zip(seq, seq[1:])\n",
        "        if t1 == \"human\" and t2 == \"ai\"\n",
        "    ]\n",
        "    lines.extend(pairs)\n",
        "    return \"\\n\\n\".join(lines)\n",
        "\n",
        "# Gradio UI ì„¤ì •\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    # â”€â”€ ì‚¬ì´ë“œë°”: ì„¸ì…˜ ê´€ë¦¬ â”€â”€\n",
        "    with gr.Sidebar():\n",
        "        session_dropdown = gr.Dropdown(\n",
        "            label=\"ì±„íŒ… ì„¸ì…˜ ì„ íƒ\",\n",
        "            choices=[],\n",
        "            value=None,\n",
        "            interactive=True\n",
        "        )\n",
        "        new_session_btn = gr.Button(\"â• ìƒˆ ì±„íŒ…\")\n",
        "        del_session_btn = gr.Button(\"ğŸ—‘ ì„¸ì…˜ ì‚­ì œ\")\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ“„ ì¸ê³µì§€ëŠ¥ PDF Q&A ì±—ë´‡\n",
        "    **ì—¬ëŸ¬ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤!**\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            file_input = gr.File(label=\"PDF íŒŒì¼ ì„ íƒ\")\n",
        "            upload_button = gr.Button(\"ğŸ“¤ ë²¡í„° DBì— ì €ì¥\")\n",
        "            show_files_button = gr.Button(\"ğŸ“š ì €ì¥ëœ ë¬¸ì„œ ë³´ê¸°\")\n",
        "            status_output = gr.Textbox(label=\"ğŸ“¢ ìƒíƒœ ë©”ì‹œì§€\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            question_input = gr.Textbox(label=\"â“ ì§ˆë¬¸ ì…ë ¥\", placeholder=\"ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì ì–´ì£¼ì„¸ìš”.\")\n",
        "            submit_button = gr.Button(\"ğŸ¤– ë‹µë³€ ë°›ê¸°\")\n",
        "            answer_output = gr.Textbox(label=\"ğŸ“ AI ë‹µë³€\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            show_history_button = gr.Button(\"ğŸ•˜ íˆìŠ¤í† ë¦¬ ë³´ê¸°\")\n",
        "            history_output = gr.Textbox(label=\"ğŸ—’ ì „ì²´ ëŒ€í™” ë‚´ì—­ | System/Human/AI Message\", lines=15, interactive=False)\n",
        "\n",
        "    # â”€â”€ ì‚¬ì´ë“œë°” ì´ë²¤íŠ¸ ë°”ì¸ë”© â”€â”€\n",
        "    def create_session():\n",
        "        global session_counter\n",
        "        sid = f\"session_{session_counter}\"\n",
        "        session_counter += 1\n",
        "        init_session(sid)\n",
        "        # Dropdown choices ê°±ì‹  & ìƒˆë¡œ ë§Œë“  ì„¸ì…˜ìœ¼ë¡œ ì„ íƒ\n",
        "        return gr.update(choices=list(history_store.keys()), value=sid)\n",
        "\n",
        "    # ì„¸ì…˜ ì‚­ì œ í•¨ìˆ˜\n",
        "    def delete_session(session_id: str):\n",
        "        history_store.pop(session_id, None)\n",
        "\n",
        "    new_session_btn.click(\n",
        "        fn=create_session,\n",
        "        inputs=None,\n",
        "        outputs=[session_dropdown]\n",
        "    )\n",
        "\n",
        "    def remove_session(sid):\n",
        "        delete_session(sid)\n",
        "        keys = list(history_store.keys())\n",
        "        new_val = keys[0] if keys else None\n",
        "        return gr.update(choices=keys, value=new_val)\n",
        "\n",
        "    del_session_btn.click(\n",
        "        fn=remove_session,\n",
        "        inputs=[session_dropdown],\n",
        "        outputs=[session_dropdown]\n",
        "    )\n",
        "\n",
        "    # â”€â”€ íŒŒì¼ ì—…ë¡œë“œ / ì§ˆë¬¸ / íˆìŠ¤í† ë¦¬ ì´ë²¤íŠ¸ â”€â”€\n",
        "    upload_button.click(add_pdf_to_db, inputs=file_input, outputs=status_output)\n",
        "    submit_button.click(answer_question, inputs=[question_input, session_dropdown], outputs=answer_output)\n",
        "    show_files_button.click(show_stored_documents, outputs=status_output)\n",
        "    show_history_button.click(show_history, inputs=[session_dropdown], outputs=history_output)\n",
        "\n",
        "# ë²¡í„° DB ë¡œë“œ í›„ ì‹¤í–‰\n",
        "# load_faiss_db()\n",
        "load_chroma_db()\n",
        "init_session(\"session_1\")\n",
        "load_chain()\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "krtuPwiOIwfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë“œë¼ì´ë¸Œ ë‚´ í´ë” ì•ˆì— ì¡´ì¬í•˜ëŠ” pdf íŒŒì¼ë“¤ ì €ì¥í•˜ëŠ” ì½”ë“œ\n",
        "# íë¦„: í´ë” ìˆœíšŒ -> pdf/md íŒŒì¼ 1ê°œ ì°¾ê¸° â†’ URL ë§¤ì¹­(ìœ ì‚¬ë„ ê¸°ë°˜) : íŒŒì¼ëª…ì„ ê°€ì§€ê³  URL ì•Œì•„ì˜¤ê¸° -> í…ìŠ¤íŠ¸ load & split(ì²­í‚¹) â†’ ë©”íƒ€ ì •ë³´ ì¶”ê°€ -> ChromaDBì— ì €ì¥(ìë™ ì„ë² ë”©)\n",
        "# íë¦„ì„ ë°˜ë³µí•˜ì—¬ ì²˜ë¦¬í•˜ëŠ” íŒŒì´í”„ë¼ì¸\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "# from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# â€” ì„¤ì • â€” #\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/Cheonan Campus All Departments (ì²œì•ˆìº í¼ìŠ¤ ëª¨ë“  í•™ê³¼)/Software Department (ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼)\"   # ìˆœíšŒí•  ìµœìƒìœ„ í´ë”\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/ChromaDB/knu_chroma_db\"         # ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "EMB_MODEL     = \"BAAI/bge-m3\"\n",
        "URL_XLSX_PATH = os.path.join(ROOT_FOLDER, \"Software Department (ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼)_url.xlsx\")\n",
        "SIMILARITY_CUTOFF = 0.7\n",
        "\n",
        "# â€” ë¡œê¹… ì„¤ì • (Colabì—ì„œë„ ë³´ì´ê²Œ) â€” #\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "handler.setFormatter(formatter)\n",
        "if not logger.hasHandlers():\n",
        "    logger.addHandler(handler)\n",
        "\n",
        "# íŒŒì¼ëª… ì •ê·œí™”: NFC â†’ í™•ì¥ì ì œê±° â†’ ê³µë°± ì œê±°\n",
        "def normalize_name(name: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFC\", name)\n",
        "    s = re.sub(r\"\\.\\w+$\", \"\", s)  # .pdf, .md ë“± ì œê±°\n",
        "    return s.replace(\" \", \"\")\n",
        "\n",
        "# 1) URL ë§¤í•‘ ë¡œë“œ\n",
        "def load_url_map(path: str) -> dict:\n",
        "    df = pd.read_excel(path)\n",
        "    return {\n",
        "        normalize_name(str(fn)): url\n",
        "        for fn, url in zip(df[\"íŒŒì¼ëª…\"], df[\"URL\"])\n",
        "    }\n",
        "URL_MAP = load_url_map(URL_XLSX_PATH)\n",
        "\n",
        "# 2) ê°€ì¥ ìœ ì‚¬í•œ URL ì°¾ì•„ì£¼ëŠ” í•¨ìˆ˜\n",
        "def find_best_url(base_norm: str, url_map: dict, cutoff: float) -> str:\n",
        "    # ì™„ì „ ì¼ì¹˜\n",
        "    if base_norm in url_map:\n",
        "        logger.info(f\"ğŸ”— URL 100% ì¼ì¹˜: '{base_norm}' â†’ {url_map[base_norm]}\")\n",
        "        return url_map[base_norm]\n",
        "\n",
        "    # ìœ ì‚¬ë„ íƒìƒ‰\n",
        "    best_key, best_score = None, 0.0\n",
        "    for key in url_map:\n",
        "        score = SequenceMatcher(None, base_norm, key).ratio()\n",
        "        if score > best_score:\n",
        "            best_key, best_score = key, score\n",
        "\n",
        "    if best_score >= cutoff:\n",
        "        logger.info(f\"ğŸ” ìœ ì‚¬ë„({best_score:.2f}) ë§¤ì¹­: '{base_norm}' â†’ '{best_key}' â†’ {url_map[best_key]}\")\n",
        "        return url_map[best_key]\n",
        "    else:\n",
        "        logger.info(f\"âŒ URL ë§¤ì¹­ ì‹¤íŒ¨({best_score:.2f}): '{base_norm}' â†’ URL ì—†ìŒ\")\n",
        "        return \"\"\n",
        "\n",
        "# 3) Loader ì„ íƒ (.pdf/.md)\n",
        "def get_loader(fp: Path):\n",
        "    ext = fp.suffix.lower()\n",
        "    if ext == \".pdf\":\n",
        "        return PyPDFLoader(str(fp))\n",
        "    if ext == \".md\":\n",
        "        return TextLoader(str(fp), encoding=\"utf-8\")\n",
        "    return None\n",
        "\n",
        "# 4) Splitter & Embedding ì¤€ë¹„\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \"â€¦\"]\n",
        ")\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL)\n",
        "\n",
        "# 5) ChromaDB ë¡œë“œ (í´ë”ê°€ ì—†ìœ¼ë©´ ë‚´ë¶€ì ìœ¼ë¡œ ìƒˆë¡œ ìƒì„±ë¨)\n",
        "db = Chroma(\n",
        "    persist_directory=PERSIST_DIR,\n",
        "    embedding_function=hf_embeddings\n",
        ")\n",
        "logger.info(\"ğŸ”„ ChromaDB ë¡œë“œ/ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "\n",
        "# 6) íŒŒì¼ ìˆœíšŒí•˜ë©° ì²­í‚¹ + ë©”íƒ€ ì¶”ê°€ + DB ì €ì¥\n",
        "for fp in Path(ROOT_FOLDER).rglob(\"*.*\"):\n",
        "    loader = get_loader(fp)\n",
        "    if loader is None:\n",
        "        continue\n",
        "\n",
        "    base_raw  = fp.name\n",
        "    base_norm = normalize_name(base_raw)\n",
        "    # department ì¶”ì¶œ (í˜„ì¬ ë£¨íŠ¸ í´ë” ê¸°ì¤€)\n",
        "    department = Path(ROOT_FOLDER).name\n",
        "\n",
        "    # ì¤‘ë³µ ì²´í¬: file_nameê³¼ departmentê°€ ëª¨ë‘ ì¼ì¹˜í•  ê²½ìš°ì—ë§Œ ì¤‘ë³µ ê°„ì£¼\n",
        "    try:\n",
        "        results = db.get(where={\"file_name\": {\"$eq\": base_raw}})\n",
        "        metadatas = results.get(\"metadatas\", [])\n",
        "        if any(md.get(\"department\") == department for md in metadatas):\n",
        "            logger.info(f\"â­ï¸ ì´ë¯¸ ì €ì¥ëœ íŒŒì¼: {base_raw} ({department}) â†’ ìŠ¤í‚µ\")\n",
        "            continue\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"â— ì¤‘ë³µ ê²€ì‚¬ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}\")\n",
        "\n",
        "    logger.info(f\"ğŸ“„ íŒŒì¼ ë¡œë“œ & ì²­í‚¹ ì‹œì‘: {fp.relative_to(ROOT_FOLDER)}\")\n",
        "    url = find_best_url(base_norm, URL_MAP, SIMILARITY_CUTOFF)\n",
        "\n",
        "    # ë¡œë“œ & ì²­í‚¹\n",
        "    try:\n",
        "        chunks = loader.load_and_split(text_splitter=text_splitter)\n",
        "        logger.info(f\"ğŸ§© ì²­í¬ ìƒì„±: {len(chunks)}ê°œ\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"âŒ '{base_raw}' ë¡œë“œ/ì²­í‚¹ ì‹¤íŒ¨: {e}\")\n",
        "        continue\n",
        "    if not chunks:\n",
        "        logger.warning(f\"âš ï¸ '{base_raw}' ë¹ˆ ì²­í¬ â†’ ê±´ë„ˆëœë‹ˆë‹¤\")\n",
        "        continue\n",
        "\n",
        "    # ë©”íƒ€ ì¶”ê°€\n",
        "    for chunk in chunks:\n",
        "        chunk.metadata.update({\n",
        "            \"file_name\":  base_raw,\n",
        "            \"department\": department,\n",
        "            \"url\":        url\n",
        "        })\n",
        "\n",
        "    # DB ì €ì¥\n",
        "    db.add_documents(chunks)\n",
        "    logger.info(f\"â• '{base_raw}' â€” {len(chunks)}ê°œ Chroma DBì— ì €ì¥ ì™„ë£Œ\")\n",
        "\n",
        "logger.info(\"ğŸ‰ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ â€” ChromaDBì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤\")"
      ],
      "metadata": {
        "id": "B7YUqoagH4Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# â€” ì„¤ì • â€” #\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/ChromaDB/knu_chroma_db\"\n",
        "EMB_MODEL   = \"BAAI/bge-m3\"\n",
        "\n",
        "# 1) DB ë¡œë“œ\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL)\n",
        "db = Chroma(persist_directory=PERSIST_DIR, embedding_function=hf_embeddings)\n",
        "\n",
        "# 2) ë©”íƒ€ì •ë³´ë§Œ êº¼ë‚´ì˜¤ê¸°\n",
        "res = db.get(include=[\"metadatas\"])\n",
        "\n",
        "# 3) ì´ ì²­í¬ ìˆ˜ ë° íŒŒì¼ëª…Â·ë¶€ì„œÂ·URL ì¶œë ¥\n",
        "metas = res[\"metadatas\"]\n",
        "print(f\"ì´ ì²­í¬ ìˆ˜: {len(metas)}\\n\")\n",
        "for meta in metas:\n",
        "    print(\n",
        "        f\"íŒŒì¼ëª…: {meta.get('file_name','Unknown')}  |  \"\n",
        "        f\"ë¶€ì„œ: {meta.get('department','Unknown')}  |  \"\n",
        "        f\"URL: {meta.get('url','')}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "PQW_Hdd07pWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import shutil\n",
        "\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/ChromaDB/knu_chroma_db\"\n",
        "\n",
        "# 1) í´ë” ìì²´ë¥¼ ë‚ ë ¤ë²„ë¦¬ê¸°\n",
        "shutil.rmtree(PERSIST_DIR)\n",
        "\n",
        "print(f\"ğŸ—‘ï¸ '{PERSIST_DIR}' í´ë”ë¥¼ ì™„ì „íˆ ì œê±°í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ-uYzmm_4XX",
        "outputId": "762699ed-051d-4758-956d-6c8c8627f516"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—‘ï¸ '/content/drive/MyDrive/ChromaDB/knu_chroma_db' í´ë”ë¥¼ ì™„ì „íˆ ì œê±°í–ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    }
  ]
}