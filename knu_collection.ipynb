{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMGh23IBaJHw9+HeRqVA3dB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KNUckle-llm/experiments/blob/main/knu_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word -> pdf íŒŒì¼ë¡œ ë³€í™˜(ë¡œì»¬)\n",
        "# Excel -> openpyxlë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ì €ì¥\n",
        "# HWP -> PDF íŒŒì¼ë¡œ ë³€í™˜(ë¡œì»¬)\n",
        "# ppt -> PDF íŒŒì¼ë¡œ ë³€í™˜(ë¡œì»¬)\n",
        "# ëª¨ë“  html í˜ì´ì§€ëŠ” mdë¡œ ì €ì¥\n",
        "# jpg, pdf(ì‚¬ì§„) -> ocrë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ì €ì¥\n",
        "\n",
        "\"\"\"\n",
        "ì•ìœ¼ë¡œ í• ì¼\n",
        "# ì›Œë“œ íŒŒì¼ -> pdf íŒŒì¼ë¡œ ë³€í™˜ ì˜ˆì‹œ(ì™„ë£Œ)\n",
        "# ì—‘ì…€ íŒŒì¼ -> pdf ë³€í™˜ í•´ì•¼í•¨(ì™„ë£Œ)\n",
        "# pdf(ì‚¬ì§„) -> pdfplumberë¡œë„ ì¶”ì¶œì´ ì•ˆë˜ë©´ ì‚¬ì§„ì´ë‹ˆ ocr ì§„í–‰í•˜ê¸°(ì™„ë£Œ)\n",
        "# jpg, png ì‚¬ì§„íŒŒì¼ -> í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ì €ì¥ (ì™„ë£Œ)\n",
        "ì „ì²˜ë¦¬ + ë¬¸ì„œ ì²­í‚¹(ë‚˜ëˆ„ê¸°) ë°©ë²• (ì§„í–‰ ì¤‘)\n",
        "\n",
        "â†’ í•™ê³¼ëŠ” ë„ˆë¬´ ì‘ê²Œ ë‚˜ëˆ”, ìº í¼ìŠ¤ë³„ë¡œ collectionì„ ë‚˜ëˆ„ê³ , ì§ˆë¬¸ ì „ì— í•´ë‹¹ collectionë§Œ ê²€ìƒ‰.\n",
        "ì‚¬ìš©ì ì§ˆë¬¸ -> ì˜ ë³€í™˜ -> í•´ë‹¹ë˜ëŠ” collectionì„ ë¶ˆëŸ¬ì™€ ì•ˆì— ì²­í¬ë“¤ì„ ì¡°íšŒí•˜ë©° ìœ ì‚¬ë„ ë†’ì€ê±¸ ê²€ìƒ‰í•œë‹¤.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JFTEu-E4kPb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R-CMJHq6cs38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf9c476-3050-4d58-e573-867395bef062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install pandas\n",
        "!pip install PyPDF2\n",
        "!pip install pdfplumber\n",
        "\n",
        "# ì—‘ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "!pip install openpyxl\n",
        "\n",
        "# ocr PaddleOCR ì‚¬ìš©\n",
        "!pip install paddleocr\n",
        "!pip install \"paddlepaddle==2.6.2\" -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
        "!apt-get install -y poppler-utils\n",
        "!pip install pdf2image\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "HMBZE6WnnMvn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# transformers ë²„ì „ì´ ê¼¬ì´ë©´ ì˜¤ë¥˜ë‚˜ë©´ ë‹¤ì‹œ ì„¤ì¹˜\n",
        "# 1. transformers ì‚­ì œ\n",
        "!pip uninstall -y transformers\n",
        "\n",
        "# 2. ì•ˆì •ì ì¸ ë²„ì „ìœ¼ë¡œ ì¬ì„¤ì¹˜ (4.40.2 ë˜ëŠ” 4.41.1 ê¶Œì¥)\n",
        "!pip install transformers==4.41.2\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TEvtLoKP1mwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain ì•„ë‹˜\n",
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ document_filesì— ìˆëŠ” íŒŒì¼ë“¤ ì „ë¶€ ì €ì¥\n",
        "# ê²½ê³  ë° ì˜¤ë¥˜ ì²˜ë¦¬ ë°©ë²•\n",
        "# incorrect startxref pointer(1) : Xref Table (ê°ì²´ ìœ„ì¹˜ ì •ë³´) ë¥¼ ì°¾ê¸° ìœ„í•œ í¬ì¸í„°ê°€ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ì†ìƒëœ ê²½ìš° ë‚˜íƒ€ë‚˜ëŠ” ê²½ê³ , ë˜ê¸´í•˜ë‚˜ ì¼ë¶€ í˜ì´ì§€ë‚˜ ê°ì²´ ëˆ„ë½ë  ìˆ˜ ìˆìŒ -> í•´ê²°ì±… pdfplumber\n",
        "# Advanced encoding /KSCms-UHC-H not implemented yet : DFê°€ í•œê¸€ ë¬¸ìì…‹(KSCms-UHC-H) ì„ ì‚¬ìš©í•˜ëŠ”ë°, PyPDF2 ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì´ ê³ ê¸‰ ì¸ì½”ë”©ì„ ì™„ë²½í•˜ê²Œ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²½ê³  -> í•´ê²°ì±… pdfplumber\n",
        "# âš ï¸ 2020-1 á„‰á…®á„€á…¡á†¼á„‰á…µá†«á„á…¥á†¼ á„‹á…¡á†«á„‚á…¢á„†á…®á†«(á„á…¥á†·á„‘á…²á„á…¥á„€á…©á†¼á„’á…¡á†¨á„Œá…¥á†«á„€á…©á†¼).pdf: í…ìŠ¤íŠ¸ ì—†ìŒ â†’ ìŠ¤í‚µ pdfê°€ ì‚¬ì§„ìœ¼ë¡œ ë˜ì–´ ìˆëŠ” ê²½ìš° ë°œìƒí•˜ëŠ” ë¬¸ì œ -> í•´ê²°ì±… ocr\n",
        "import io, os, re, unicodedata, pytz, warnings, logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pdfplumber\n",
        "from datetime import datetime\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from chromadb import PersistentClient\n",
        "from paddleocr import PaddleOCR\n",
        "from pdf2image import convert_from_path\n",
        "from difflib import get_close_matches, SequenceMatcher\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='pdfminer')\n",
        "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
        "\n",
        "# ì„¤ì •\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/chroma_index\"\n",
        "campus_name = \"cheonan\"  # ë˜ëŠ” \"gongju\", \"yesan\", cheonan\n",
        "COLLECTION_NAME = f\"knu_{campus_name}_collection\"\n",
        "# ê³¼ê±°: COLLECTION_NAME = \"knu_collection\" í˜„ì¬ : ìº í¼ìŠ¤ë³„ë¡œ ì»¬ë ‰ì…˜ ìƒì„±\n",
        "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/document files Cheonan Campus\"     # ì—¬ê¸°ë§Œ ë°”ê¾¸ê¸°(ê²½ë¡œ)\n",
        "URL_MAPPING_SUFFIX = \"_url.xlsx\"\n",
        "\n",
        "# PaddleOCR ì´ˆê¸°í™” (ìµœì´ˆ 1íšŒë§Œ)\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='korean')\n",
        "\n",
        "KST = pytz.timezone('Asia/Seoul')\n",
        "model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
        "client = PersistentClient(path=PERSIST_DIR)\n",
        "collection = client.get_or_create_collection(name=COLLECTION_NAME)\n",
        "existing_ids = set(collection.get(limit=None)['ids'])\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def clean_text(text):\n",
        "    # ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ + ë„ˆë¬´ ì§§ì€ ì¤„ ì œê±°\n",
        "    text = unicodedata.normalize(\"NFC\", str(text))\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[â– â—†â—â€»â–¶â–·â–²â†’â—‡]', '', text)  # ë¶ˆí•„ìš” ê¸°í˜¸ ì œê±°\n",
        "    lines = [line.strip() for line in text.split('\\n') if len(line.strip()) > 10]\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "# ì²­í‚¹ ì „ëµ\n",
        "def split_chunks(text, max_length=500, overlap=100):\n",
        "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
        "    all_chunks = []\n",
        "\n",
        "    for para in paragraphs:\n",
        "        # ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', para)\n",
        "        current_chunk = \"\"\n",
        "\n",
        "        for sentence in sentences:\n",
        "            if len(current_chunk) + len(sentence) <= max_length:\n",
        "                current_chunk += sentence + \" \"\n",
        "            else:\n",
        "                all_chunks.append(current_chunk.strip())\n",
        "                current_chunk = current_chunk[-overlap:] + sentence + \" \"\n",
        "\n",
        "        if current_chunk.strip():\n",
        "            all_chunks.append(current_chunk.strip())\n",
        "\n",
        "    return [chunk for chunk in all_chunks if len(chunk) > 30]\n",
        "\n",
        "# âœ… íŒŒì¼ëª… ì •ê·œí™” í•¨ìˆ˜\n",
        "def normalize_filename(name: str) -> str:\n",
        "    # 1. NFC ì •ê·œí™” (í•œê¸€ ìì†Œ ë¶„ë¦¬ ë°©ì§€)\n",
        "    name = unicodedata.normalize(\"NFC\", str(name))\n",
        "    # 2. ê³µë°± ì–‘ìª½ ì œê±°\n",
        "    name = name.strip()\n",
        "    # 3. ê´„í˜¸, ë”°ì˜´í‘œ, í•˜ì´í”ˆ í¬í•¨í•œ ë‹¤ì–‘í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "    name = re.sub(r\"[\\\\/*?\\\"<>|â€›â€˜â€™â€œâ€'ã€Œã€ã€ã€‘Â·~!@#$%^&+=;,â€¦ã†â€”âˆ’â€’â€“â€•â€¢â€»â†’â†â†‘â†“â˜…â˜†â™¥â™¡â€¢â€²â€³\\[\\]\\(\\)\\{\\},\\-]\", '', name)\n",
        "    return name\n",
        "\n",
        "# âœ… ìœ ì‚¬ íŒŒì¼ëª…ì„ í†µí•œ URL ë§¤í•‘ í•¨ìˆ˜\n",
        "def find_best_url(base_name_norm, url_mapping, cutoff=0.7):\n",
        "    # ìœ ì‚¬ë„ 100%\n",
        "    if base_name_norm in url_mapping:\n",
        "        return url_mapping[base_name_norm]\n",
        "\n",
        "    # ì´í›„ íŒŒì¼ëª… ë¶€ì¼ì¹˜ì‹œ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­\n",
        "    # ëª¨ë“  í›„ë³´ì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°\n",
        "    candidates = []\n",
        "    for key in url_mapping.keys():\n",
        "        sim = SequenceMatcher(None, base_name_norm, key).ratio()\n",
        "        candidates.append((key, sim))\n",
        "\n",
        "    # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ í•­ëª© ì¶”ì¶œ\n",
        "    best_match = max(candidates, key=lambda x: x[1])\n",
        "    match_name, best_score = best_match\n",
        "\n",
        "    if best_score >= cutoff:\n",
        "        print(f\"âš ï¸ íŒŒì¼ëª… ë¶ˆì¼ì¹˜ â†’ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ì‚¬ìš©: '{base_name_norm}' â†’ '{match_name}' (ìœ ì‚¬ë„: {best_score:.2f})\")\n",
        "        return url_mapping[match_name]\n",
        "    else:\n",
        "        print(f\"â›” íŒŒì¼ëª… ë§¤ì¹­ ì‹¤íŒ¨: '{base_name_norm}' â†’ ê°€ì¥ ë¹„ìŠ·í•œ í•­ëª©: '{match_name}' (ìœ ì‚¬ë„: {best_score:.2f})\")\n",
        "        return \"ì¶œì²˜ URL ì—†ìŒ\"\n",
        "\n",
        "# OCR í•¨ìˆ˜(ì‚¬ì§„ íŒŒì¼ .jpg, .jpeg, .png)\n",
        "def extract_text_from_image(image_path):\n",
        "    try:\n",
        "        from PIL import Image\n",
        "        img = Image.open(image_path).convert(\"RGB\")\n",
        "        image_np = np.array(img)[:, :, ::-1]  # RGB â†’ BGR\n",
        "        result = ocr.ocr(image_np, cls=True)\n",
        "        text = \"\\n\".join([line[1][0] for line in result[0]])\n",
        "        if text.strip():\n",
        "            print(f\"ğŸ–¼ï¸ {os.path.basename(image_path)}: ì´ë¯¸ì§€ OCR ì¶”ì¶œ ì„±ê³µ\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ [ì´ë¯¸ì§€ OCR ì‹¤íŒ¨] {image_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# OCR í•¨ìˆ˜(pdfì— í…ìŠ¤íŠ¸ë§ê³  ì‚¬ì§„ì´ ì €ì¥ëœ ê²½ìš°)\n",
        "def extract_text_with_paddleocr(pdf_path):\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path, dpi=300, poppler_path=\"/usr/bin\")\n",
        "        full_text = \"\"\n",
        "        for i, page in enumerate(images):\n",
        "            image_np = np.array(page)[:, :, ::-1]  # RGB -> BGR\n",
        "            result = ocr.ocr(image_np, cls=True)\n",
        "            for line in result[0]:\n",
        "                full_text += line[1][0] + \"\\n\"\n",
        "        return full_text\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ [OCR ì‹¤íŒ¨] {os.path.basename(pdf_path)}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ (PyPDF2 -> pdfplumber -> ocr ìˆœìœ¼ë¡œ ëª¨ë“  pdf íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ)\n",
        "def read_file(filepath):\n",
        "    def try_pypdf2(path):\n",
        "        class SkipHandler(logging.Handler):\n",
        "            def emit(self, record):\n",
        "                if \"incorrect startxref pointer\" in record.getMessage():\n",
        "                    raise ValueError(\"skip_due_to_incorrect_startxref\")\n",
        "\n",
        "        handler = SkipHandler()\n",
        "        logger = logging.getLogger(\"PyPDF2._reader\")\n",
        "        logger.addHandler(handler)\n",
        "        logger.setLevel(logging.WARNING)\n",
        "\n",
        "        try:\n",
        "            with warnings.catch_warnings(record=True) as w:\n",
        "                warnings.simplefilter(\"always\")\n",
        "                reader = PdfReader(path)\n",
        "                text = \"\"\n",
        "                for page in reader.pages:\n",
        "                    text += page.extract_text() or \"\"\n",
        "                for warning in w:\n",
        "                    msg = str(warning.message)\n",
        "                    if \"KSCms-UHC-H\" in msg:\n",
        "                        print(f\"âš ï¸ {os.path.basename(path)}: í•œê¸€ ê¸€ê¼´ ë¯¸ì§€ì› (KSCms-UHC-H) â†’ pdfplumber ì‹œë„\")\n",
        "                        return \"\"\n",
        "                return text\n",
        "        except ValueError as ve:\n",
        "            if \"skip_due_to_incorrect_startxref\" in str(ve):\n",
        "                print(f\"âš ï¸ {os.path.basename(path)}: êµ¬ì¡° ì†ìƒ (startxref) â†’ pdfplumber ì‹œë„\")\n",
        "                return \"\"\n",
        "            else:\n",
        "                raise\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ [PyPDF2 ì‹¤íŒ¨] {path}: {e}\")\n",
        "            return \"\"\n",
        "        finally:\n",
        "            logger.removeHandler(handler)\n",
        "\n",
        "    def try_pdfplumber(path):\n",
        "        try:\n",
        "            import pdfplumber\n",
        "            with pdfplumber.open(path) as pdf:\n",
        "                text = \"\"\n",
        "                for page in pdf.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        text += page_text + \"\\n\"\n",
        "                if text.strip():\n",
        "                    print(f\"ğŸ“„ {os.path.basename(path)}: pdfplumber ì¶”ì¶œ ì„±ê³µ\")\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ [pdfplumber ì‹¤íŒ¨] {path}: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    if filepath.endswith(\".pdf\"):\n",
        "        text = try_pypdf2(filepath)\n",
        "        if not text.strip():\n",
        "            text = try_pdfplumber(filepath)\n",
        "        return text\n",
        "\n",
        "    elif filepath.endswith(\".md\"):\n",
        "        try:\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                return f.read()\n",
        "        except:\n",
        "            return \"\"\n",
        "\n",
        "    elif filepath.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        return extract_text_from_image(filepath)\n",
        "\n",
        "    elif filepath.lower().endswith(('.xlsx', '.xls')):\n",
        "        try:\n",
        "            xls = pd.read_excel(filepath, sheet_name=None, dtype=str)\n",
        "            all_text = \"\"\n",
        "            for sheet_name, df in xls.items():\n",
        "                df = df.fillna(\"\")\n",
        "                all_text += f\"\\n=== ì‹œíŠ¸: {sheet_name} ===\\n\"\n",
        "                all_text += \"\\n\".join([\"\\t\".join(row) for row in df.values.tolist()]) + \"\\n\"\n",
        "            return all_text.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {filepath} ({e})\")\n",
        "            return \"\"\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "def get_all_files(folder):\n",
        "    all_files = []\n",
        "    for dirpath, _, filenames in os.walk(folder):\n",
        "        for f in filenames:\n",
        "            if f.endswith(('.pdf', '.md', '.jpg', '.jpeg', '.png', '.xlsx', '.xls')):\n",
        "                all_files.append(os.path.join(dirpath, f))\n",
        "    return all_files\n",
        "\n",
        "def extract_category(file_path, base_folder):\n",
        "    rel_path = os.path.relpath(file_path, start=base_folder)\n",
        "    parts = rel_path.split(os.sep)\n",
        "    return parts[0] if len(parts) > 1 else \"ê¸°íƒ€\"\n",
        "\n",
        "def build_metadata(file_path, base_folder, base_name, source_url, ext):\n",
        "    category = extract_category(file_path, base_folder)\n",
        "    department_path = os.path.relpath(base_folder, ROOT_FOLDER)\n",
        "\n",
        "    # í™•ì¥ì ê¸°ë°˜ìœ¼ë¡œ source_type ë¶„ê¸°\n",
        "    if ext == \".pdf\":\n",
        "        source_type = \"pdf\"\n",
        "    elif ext == \".md\":\n",
        "        source_type = \"markdown\"\n",
        "    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "        source_type = \"image\"\n",
        "    elif ext in [\".xlsx\", \".xls\"]:\n",
        "        source_type = \"excel\"\n",
        "    else:\n",
        "        source_type = \"etc\"  # í˜¹ì‹œ ëª¨ë¥¼ í™•ì¥ìì— ëŒ€í•œ ëŒ€ë¹„\n",
        "\n",
        "    return {\n",
        "        \"file_name\": base_name,\n",
        "        \"department\": department_path,\n",
        "        \"category\": category,\n",
        "        \"source_type\": source_type,\n",
        "        \"source_url\": source_url,\n",
        "        \"date\": datetime.now(KST).isoformat()\n",
        "    }\n",
        "\n",
        "total_added = 0\n",
        "failed_matches = []\n",
        "\n",
        "# ì—‘ì…€ ê¸°ì¤€ìœ¼ë¡œ ì €ì¥\n",
        "for dirpath, _, filenames in os.walk(ROOT_FOLDER):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith(URL_MAPPING_SUFFIX):\n",
        "            folder = dirpath  # ì—‘ì…€ ìœ„ì¹˜ í´ë” = ê¸°ì¤€ í´ë”\n",
        "            dept_folder_name = os.path.basename(folder)\n",
        "            url_file = os.path.join(folder, filename)\n",
        "\n",
        "            try:\n",
        "                url_df = pd.read_excel(url_file)\n",
        "                url_df.columns = url_df.columns.str.strip()\n",
        "                url_df['íŒŒì¼ëª…_ì •ê·œí™”'] = url_df['íŒŒì¼ëª…'].apply(lambda x: normalize_filename(os.path.splitext(str(x))[0]))\n",
        "                url_df['URL'] = url_df['URL'].astype(str).str.strip()\n",
        "                url_mapping = dict(zip(url_df['íŒŒì¼ëª…_ì •ê·œí™”'], url_df['URL']))\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ URL ë§¤í•‘ ì‹¤íŒ¨: {url_file} ({e})\")\n",
        "                continue\n",
        "\n",
        "            file_paths = get_all_files(folder)\n",
        "\n",
        "            for file_path in file_paths:\n",
        "                file_name = os.path.basename(file_path)\n",
        "                base_name = os.path.splitext(file_name)[0]\n",
        "                ext = os.path.splitext(file_name)[1].lower()\n",
        "\n",
        "                if file_name.endswith(URL_MAPPING_SUFFIX):\n",
        "                    continue\n",
        "\n",
        "                # í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼ê°€ ê³µë°±ì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¼ ê²½ìš° í•´ë‹¹ pdf íŒŒì¼ì€ ì‚¬ì§„ìœ¼ë¡œ êµ¬ì„±ëœ ê²½ìš°ì„\n",
        "                raw_text = read_file(file_path)\n",
        "                if not raw_text.strip():\n",
        "                    print(f\"âš ï¸ {file_name}: í…ìŠ¤íŠ¸ ì—†ìŒ â†’ PaddleOCR ì‹œë„\")\n",
        "                    raw_text = extract_text_with_paddleocr(file_path)\n",
        "\n",
        "                # ê·¸ë˜ë„ í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ ìµœì¢… ìŠ¤í‚µ\n",
        "                if not raw_text.strip():\n",
        "                    print(f\"â›” {file_name}: PyPDF2, pdfplumber, PaddleOCR ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ â†’ ìŠ¤í‚µ\")\n",
        "                    continue\n",
        "\n",
        "                # âœ… URL ë§¤í•‘ ì‹¤íŒ¨í•˜ë©´ ë°”ë¡œ ì „ì²´ ìŠ¤í‚µ\n",
        "                norm_base = normalize_filename(base_name)\n",
        "                source_url = find_best_url(norm_base, url_mapping)\n",
        "                if source_url == \"ì¶œì²˜ URL ì—†ìŒ\":\n",
        "                    failed_matches.append((base_name, dept_folder_name))\n",
        "                    print(f\"â›” {file_name}: URL ë§¤ì¹­ ì‹¤íŒ¨ (â†’ {norm_base}) â†’ ë²¡í„° ì €ì¥ ìŠ¤í‚µ\")\n",
        "                    continue\n",
        "\n",
        "                cleaned = clean_text(raw_text) # ì „ì²˜ë¦¬ ì „ëµ í•¨ìˆ˜ í˜¸ì¶œ\n",
        "                chunks = split_chunks(cleaned, max_length=500, overlap=100) # ì²­í‚¹ ì „ëµ í•¨ìˆ˜ í˜¸ì¶œ\n",
        "                embeddings = model.encode(chunks).tolist()\n",
        "                ids = [f\"{dept_folder_name}_{base_name}_chunk_{i}\" for i in range(len(chunks))]\n",
        "\n",
        "                new_chunks, new_embeddings, new_ids, new_metadatas = [], [], [], []\n",
        "\n",
        "                for chunk, emb, id_ in zip(chunks, embeddings, ids):\n",
        "                    if id_ not in existing_ids:\n",
        "                        meta = build_metadata(file_path, folder, base_name, source_url, ext)\n",
        "                        new_chunks.append(chunk)\n",
        "                        new_embeddings.append(emb)\n",
        "                        new_ids.append(id_)\n",
        "                        new_metadatas.append(meta)\n",
        "\n",
        "                if new_chunks:\n",
        "                    collection.add(\n",
        "                        documents=new_chunks,\n",
        "                        embeddings=new_embeddings,\n",
        "                        metadatas=new_metadatas,\n",
        "                        ids=new_ids\n",
        "                    )\n",
        "                    print(f\"âœ… {file_name}: {len(new_chunks)}ê°œ ì €ì¥ ì™„ë£Œ\")\n",
        "                    total_added += len(new_chunks)\n",
        "                else:\n",
        "                    print(f\"ğŸŸ¦ {file_name}: ì¤‘ë³µ ì²­í¬ ì¡´ì¬ â†’ ìŠ¤í‚µ\")\n",
        "\n",
        "\n",
        "if failed_matches:\n",
        "    print(f\"\\nURL ë§¤í•‘ ì‹¤íŒ¨ íŒŒì¼ ìˆ˜: {len(failed_matches)}\")\n",
        "    for base_name, dept in failed_matches:\n",
        "        print(f\"ğŸ“‚ [{dept}] - {base_name}\")\n",
        "else:\n",
        "    print(\"\\nâœ… ëª¨ë“  íŒŒì¼ì´ URL ë§¤í•‘ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(f\"\\nğŸ‰ ì´ ì €ì¥ëœ ì‹ ê·œ ì²­í¬ ìˆ˜: {total_added}\")"
      ],
      "metadata": {
        "id": "YNaggdr8dqHb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from chromadb import PersistentClient\n",
        "\n",
        "# ì„¤ì •\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/chroma_index\"\n",
        "COLLECTION_NAME = \"knu_cheonan_collection\"\n",
        "\n",
        "client = PersistentClient(path=PERSIST_DIR)\n",
        "collection = client.get_or_create_collection(name=COLLECTION_NAME)\n",
        "\n",
        "# ì „ì²´ ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "results = collection.get(limit=None, include=[\"documents\", \"metadatas\", \"embeddings\"])\n",
        "total_docs = len(results['ids'])\n",
        "\n",
        "print(f\"\\nğŸ“¦ ì „ì²´ ì €ì¥ëœ ë²¡í„° ìˆ˜: {total_docs}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 10ê°œ ë¬´ì‘ìœ„ ì¶”ì¶œ\n",
        "sample_indices = random.sample(range(total_docs), min(10, total_docs))\n",
        "\n",
        "for i in sample_indices:\n",
        "    doc_id = results[\"ids\"][i]\n",
        "    metadata = results[\"metadatas\"][i]\n",
        "    doc_text = results[\"documents\"][i].strip().replace(\"\\n\", \" \")\n",
        "    embedding = results[\"embeddings\"][i]\n",
        "\n",
        "    print(f\"ğŸ”¹ ID: {doc_id}\")\n",
        "    print(f\"   ğŸ“ íŒŒì¼ëª…: {metadata.get('file_name')}\")\n",
        "    print(f\"   ğŸ« ë¶€ì„œ: {metadata.get('department')}\")\n",
        "    print(f\"   ğŸ“‚ ì¹´í…Œê³ ë¦¬: {metadata.get('category')}\")\n",
        "    print(f\"   ğŸ“„ íƒ€ì…: {metadata.get('source_type')}\")\n",
        "    print(f\"   ğŸŒ URL: {metadata.get('source_url')}\")\n",
        "    print(f\"   ğŸ“… ë‚ ì§œ: {metadata.get('date')[:10]}\")\n",
        "    print(f\"   ğŸ’¬ ì²­í¬ ë¬¸ì¥: {doc_text[:200]}...\")  # 200ìê¹Œì§€ë§Œ í‘œì‹œ\n",
        "    print(f\"   ğŸ§  ë²¡í„° ê¸¸ì´: {len(embedding)}\")\n",
        "    print(f\"   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: {embedding[:5]}\")\n",
        "    print(\"-\" * 70)"
      ],
      "metadata": {
        "id": "F0gqtPA8wvRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089b1b44-1e79-43da-c9e7-4b83aeb153b1",
        "collapsed": true
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¦ ì „ì²´ ì €ì¥ëœ ë²¡í„° ìˆ˜: 1095\n",
            "======================================================================\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_á„€á…©á†¼á„€á…§á†¯ á„€á…²á„Œá…¥á†¼á„‹á…µá†¸á„‚á…µá„ƒá…¡._chunk_0\n",
            "   ğŸ“ íŒŒì¼ëª…: á„€á…©á†¼á„€á…§á†¯ á„€á…²á„Œá…¥á†¼á„‹á…µá†¸á„‚á…µá„ƒá…¡.\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„€á…²á„Œá…¥á†¼á„Œá…¡á„…á…­á„‰á…µá†¯)\n",
            "   ğŸ“„ íƒ€ì…: markdown\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1426/293859/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: # ê³µê²° ê·œì •ì…ë‹ˆë‹¤. **ì¶œì²˜:** [https://sw.kongju.ac.kr/bbs/ZD1180/1426/293859/artclView.do](https://sw.kongju.ac.kr/bbs/ZD1180/1426/293859/artclView.do) **ì‘ì„±ì:** ì„ì„±ì²  **ì‘ì„±ì¼:** 2024.03.07 ## ë³¸ë¬¸ <ê³µê²° ë° ë³‘ê²° ê´€ë ¨ êµ­ë¦½ê³µì£¼ëŒ€í•™...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [ 0.04841236  0.03040045  0.10784128  0.02828371 -0.08069456]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_2022á„’á…¡á†¨á„‚á…§á†«á„ƒá…© á„ƒá…©á†¼á„€á…¨á„‡á…¡á†¼á„’á…¡á†¨ ã€Œá„’á…¡á†«á„€á…®á†¨á„Œá…©á„‘á…¨á„€á…©á†¼á„‰á…¡ã€ á„‹á…©á„‘á…³á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…§á†«á„Œá…¡á†¼á„‰á…µá†¯á„‰á…³á†¸ á„Œá…µá„‹á…¯á†«á„Œá…¡ á„†á…©á„Œá…µá†¸_chunk_3\n",
            "   ğŸ“ íŒŒì¼ëª…: 2022á„’á…¡á†¨á„‚á…§á†«á„ƒá…© á„ƒá…©á†¼á„€á…¨á„‡á…¡á†¼á„’á…¡á†¨ ã€Œá„’á…¡á†«á„€á…®á†¨á„Œá…©á„‘á…¨á„€á…©á†¼á„‰á…¡ã€ á„‹á…©á„‘á…³á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…§á†«á„Œá…¡á†¼á„‰á…µá†¯á„‰á…³á†¸ á„Œá…µá„‹á…¯á†«á„Œá…¡ á„†á…©á„Œá…µá†¸\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„’á…¡á†¨á„€á…ªá„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: markdown\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1423/261929/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: í•˜ë©°, ì†Œì† í•™ê³¼ì— í˜„ì¥ì‹¤ìŠµ êµê³¼ëª©ì´ ê°œì„¤ë˜ëŠ” ê²½ìš° ì „ê³µê³¼ëª©ìœ¼ë¡œ ìˆ˜ê°• ê°€ëŠ¥ ë¶™ì„ 1. í˜„ì¥ì‹¤ìŠµ ìš´ì˜ê³„íšì„œ 1ë¶€. 2. [í•™ìƒ ì œì¶œ ì„œì‹] ì‹ ì²­ì„œ 1ë¶€. 3. ê´€ë ¨ê³µë¬¸ 1ë¶€. ë. ## ì²¨ë¶€íŒŒì¼ - [https://sw.kongju.ac.kr/bbs/ZD1180/1423/471463/download.do](https://sw.kongju.ac.kr/bbs/Z...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [ 0.07321277  0.08540119  0.06262037  0.06024772 -0.04298493]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_á„‰á…¥á†¼á„Œá…¥á†¨á„‹á…®á„‰á…®á„Œá…¡á†¼á„’á…¡á†¨á„€á…³á†· á„Œá…³á†¼á„‡á…µá†¼á„‘á…¡á„‹á…µá†¯ á„€á…©á†¼á„‹á…² á„‹á…¡á†«á„‚á…¢_chunk_1\n",
            "   ğŸ“ íŒŒì¼ëª…: á„‰á…¥á†¼á„Œá…¥á†¨á„‹á…®á„‰á…®á„Œá…¡á†¼á„’á…¡á†¨á„€á…³á†· á„Œá…³á†¼á„‡á…µá†¼á„‘á…¡á„‹á…µá†¯ á„€á…©á†¼á„‹á…² á„‹á…¡á†«á„‚á…¢\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„’á…¡á†¨á„€á…ªá„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: markdown\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1423/249654/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: ë°”ëë‹ˆë‹¤ . ì„±ì ìš°ìˆ˜ì¥í•™ê¸ˆ ì œì¶œê¸°í•œ : 2.6 (ì¼) ê³µí†µì ìœ¼ë¡œ ë„¤ì´ë²„ í´ë¼ìš°ë“œì— bitnine@naver.com ì—ê²Œ \"2021 í•™ë…„ 2 í•™ê¸° ì„±ì ìš°ìˆ˜ \" í´ë”ë¥¼ ê³µìœ í•©ë‹ˆë‹¤ . í˜„ì‹œê°„ë¶€ë¡œ ê¸°ì¡´ ê³µìœ  ë˜ì—ˆë˜ ìë£Œë¥¼ ëª¨ë‘ í•´ì œ í•˜ì˜€ìœ¼ë‹ˆ ë‹¤ì‹œ ê³µìœ ì‹ ì²­ ë°”ëë‹ˆë‹¤ í´ë”êµ¬ì¡° í•™ë²ˆ _ì´ë¦„ <- ìµœìƒìœ„ í´ë”ì´ë©° 200901234_í™ê¸¸ë™ ê³¼ ê°™ì´ ìƒì„± - ì„±ì ìš°ìˆ˜ì¥í•™ê¸ˆ ...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [-0.02348396 -0.00345887 -0.00317589  0.02142402 -0.05858001]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_(á„‘á…µá†¯á„ƒá…©á†¨)2021-1 á„‰á…®á„€á…¡á†¼á„‰á…µá†«á„á…¥á†¼ á„‹á…¡á†«á„‚á…¢á„†á…®á†«(á„á…¥á†·á„‘á…²á„á…¥á„€á…©á†¼á„’á…¡á†¨á„Œá…¥á†«á„€á…©á†¼)_chunk_14\n",
            "   ğŸ“ íŒŒì¼ëª…: (á„‘á…µá†¯á„ƒá…©á†¨)2021-1 á„‰á…®á„€á…¡á†¼á„‰á…µá†«á„á…¥á†¼ á„‹á…¡á†«á„‚á…¢á„†á…®á†«(á„á…¥á†·á„‘á…²á„á…¥á„€á…©á†¼á„’á…¡á†¨á„Œá…¥á†«á„€á…©á†¼)\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„’á…¡á†¨á„€á…ªá„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: pdf\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1423/208894/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: ì›” ì´ë‚´ì— ì¡¸ì—…ë…¼ë¬¸ ê³„íšì„œ [ë³„ì§€ì„œì‹ (1)]ì„ ì „ê³µì£¼ì„ì—ê²Œ ì œì¶œí•˜ì—¬ ìŠ¹ì¸ì„ ë°›ì•„ì•¼ í•œë‹¤. â‘¡ ì œì¶œí•œ ì¡¸ì—…ë…¼ë¬¸ ê³„íšì„œë¥¼ ë³€ê²½í•˜ê³ ì í•  ë•Œì—ëŠ” ì†Œì† ì „ê³µì£¼ì„ì˜ ìŠ¹ì¸ì„ ì–»ì–´ì•¼ í•œë‹¤. â‘¢ ë‹¨ë…ì—°êµ¬ë¥¼ ì›ì¹™ìœ¼ë¡œ í•˜ë˜, ì§€ë„êµìˆ˜ì˜ ìŠ¹ì¸ í•˜ì— 3ì¸ ì´ë‚´ì˜ ê³µë™ì—°êµ¬ë¥¼ í—ˆìš©í•  ìˆ˜ ìˆë‹¤. â‘£ ì§€ë„êµìˆ˜ëŠ” ì¡¸ì—…ë…¼ë¬¸ì˜ ìë£Œì¤€ë¹„ , ì‘ì„± ë° ë°œí‘œ ë“±ì— ê´€í•œ ì‚¬í•­ì„ ì§€ë„í•œë‹¤ . ì œ5...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [ 0.04314197  0.07849857  0.07001641  0.04382179 -0.01814381]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_1á„’á…¡á†¨á„‚á…§á†« á„Œá…µá†¨á„‹á…¥á†¸á„’á…³á†¼á„†á…µá„€á…¥á†·á„‰á…¡ á„‹á…¡á†«á„‚á…¢_chunk_3\n",
            "   ğŸ“ íŒŒì¼ëª…: 1á„’á…¡á†¨á„‚á…§á†« á„Œá…µá†¨á„‹á…¥á†¸á„’á…³á†¼á„†á…µá„€á…¥á†·á„‰á…¡ á„‹á…¡á†«á„‚á…¢\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„á…³á†¨á„€á…¡á†¼á„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: pdf\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1424/208934/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: ì§ì—…ì— ì í•©í•œì§€ , ì–´ë–¤ í™˜ê²½ì´ ê·¸ ê°œì¸ì—ê²Œ ì í•©í•œì§€ , ì–´ë–¤ ì‚¬ëŒë“¤ê³¼ ì¼í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ëŠ”ì§€ ë“±ì— ê´€í•œ ì •ë³´ë¥¼ ì œì‹œí•˜ëŠ” ì²™ë„ë³„ ì ìˆ˜(GOT, BIS, PSS)ê°€ ì‚°ì¶œë©ë‹ˆë‹¤ . â—‹ STRONG ì§ì—…í¥ë¯¸ê²€ì‚¬ì˜ ì´ë¡ ì  ê·¼ê±° Lowman(1991) ì€ â€œìì‹ ì˜ ì§ì—…ê³¼ ì¡°ì§ì— ì˜ ë§ëŠ” ì‚¬ëŒë“¤ì€ ê·¸ë ‡ì§€ ì•Šì€ ì‚¬ëŒë“¤ë³´ë‹¤ ê·¸ ì¼ì— ëŒ€í•œ ë§Œì¡± ë„ê°€ ë” ë†’ê³ , ì§ì—…ì„ ê³„ì†...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [-0.01110026  0.0588187  -0.01232119  0.01703704 -0.04225011]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_á„á…©á„…á…©á„‚á…¡19 á„ƒá…¢á„‹á…³á†¼ á„‹á…¡á†«á„‚á…¢_chunk_1\n",
            "   ğŸ“ íŒŒì¼ëª…: á„á…©á„…á…©á„‚á…¡19 á„ƒá…¢á„‹á…³á†¼ á„‹á…¡á†«á„‚á…¢\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„’á…¡á†¨á„€á…ªá„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: markdown\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1423/251794/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: ê³¼ í™ˆí˜ì´ì§€ íŒì—…ì— ìˆëŠ” ì„¤ë¬¸ì— ì‹ ì†íˆ ì‘ë‹µ í•™ê³¼ ë³´ê³  ( http://naver.me/FIpapnll ) ê³µê³¼ëŒ€í•™ ë³´ê³  ( http://naver.me/x78lfGvQ ) 2. ê³µê²°ì²˜ë¦¬ ì•ˆë‚´ - ë³¸ì¸í™•ì§„ : ìœ„ 1ë²ˆì˜ 2ê°œì˜ ì„¤ë¬¸ì— ì‘ë‹µ -> ì¹˜ë£Œ ì˜ í•˜ê¸° -> ê²©ë¦¬í•´ì œí›„ ë“±êµì‹œ ë¶™ì„ íŒŒì¼ì˜ ê³µê²°ì‹ ì²­ì„œ & ì¦ë¹™ í•™ê³¼ì‚¬ë¬´ì‹¤(8ê³µ 801í˜¸)ì œì¶œ - ë°€ì ‘ì ‘ì´‰(...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [ 0.01281242  0.02225454  0.02842411  0.01811122 -0.04218608]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_[á„Œá…¥á†«á„’á…¡á†¨á„‰á…¢á†¼] 2024á„’á…¡á†¨á„‚á…§á†«á„ƒá…© 1á„’á…¡á†¨á„€á…µ á„á…®á„€á…¡á„‰á…®á„€á…¡á†¼ á„‹á…¡á†«á„‚á…¢_chunk_1\n",
            "   ğŸ“ íŒŒì¼ëª…: [á„Œá…¥á†«á„’á…¡á†¨á„‰á…¢á†¼] 2024á„’á…¡á†¨á„‚á…§á†«á„ƒá…© 1á„’á…¡á†¨á„€á…µ á„á…®á„€á…¡á„‰á…®á„€á…¡á†¼ á„‹á…¡á†«á„‚á…¢\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„’á…¡á†¨á„€á…ªá„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: markdown\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1423/293370/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: .02.29 ## ë³¸ë¬¸ 2024í•™ë…„ë„ 1í•™ê¸° ì¶”ê°€ìˆ˜ê°• ì•ˆë‚´ ì•„ë˜ êµê³¼ëª©ì— ëŒ€í•´ì„œ í•™ê³¼ ìì²´ì ìœ¼ë¡œ ì¶”ê°€ìˆ˜ê°• ì ‘ìˆ˜ë¥¼ ë°›ìœ¼ë‹ˆ ì¶”ê°€ìˆ˜ê°•ì„ í•˜ê³ ì í•˜ëŠ” í•™ìƒì€ í•´ë‹¹ ì¼ì‹œì— ì‹ ì²­ ë°”ëë‹ˆë‹¤. - ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê°•ì¢Œì— ëŒ€í•´ì„œëŠ” êµìˆ˜ë‹˜ ì°¾ì•„ê°€ê³  ì—°ë½ í•´ë„ ì†Œìš© ì—…ìŒ, í•™ê³¼ì—ì„œë§Œ ë°›ìŒ - ê·¸ ì™¸ ê³¼ëª©ì€ \"ìˆ˜ê°•ì •ì› ì´ˆê³¼ êµê³¼ëª© ì¶”ê°€ ìˆ˜ê°• í™•ì¸ì„œ(ì‹ ì„œì‹)\"ë¥¼ ì‘ì„±(ë‹´ë‹¹êµìˆ˜ ë‚ ì¸...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [0.01500241 0.0320567  0.03864136 0.01245426 0.00263759]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_á„‰á…µá†«á„‹á…µá†¸á„‰á…¢á†¼ á„‰á…®á„€á…¡á†¼á„€á…ªá„†á…©á†¨ á„†á…©á†¨á„…á…©á†¨_chunk_0\n",
            "   ğŸ“ íŒŒì¼ëª…: á„‰á…µá†«á„‹á…µá†¸á„‰á…¢á†¼ á„‰á…®á„€á…¡á†¼á„€á…ªá„†á…©á†¨ á„†á…©á†¨á„…á…©á†¨\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„’á…¡á†¨á„€á…ªá„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: excel\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1423/208825/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: === ì‹œíŠ¸: Export === 1001019 01 ì›ì–´ë¯¼ì‹¤ìš©ì˜ì–´â…  ì²œì•ˆìº í¼ìŠ¤ êµí•„ 1 2 2 0 ì›”1 ì›”2 2ê³µ404 20 íƒ1 02 ì›ì–´ë¯¼ì‹¤ìš©ì˜ì–´â…  ì²œì•ˆìº í¼ìŠ¤ êµí•„ 1 2 2 0 ì›”3 ì›”4 2ê³µ404 20 03 ì›ì–´ë¯¼ì‹¤ìš©ì˜ì–´â…  ì²œì•ˆìº í¼ìŠ¤ êµí•„ 1 2 2 0 ì›”5 ì›”6 2ê³µ404 20 04 ì›ì–´ë¯¼ì‹¤ìš©ì˜ì–´â…  ì²œì•ˆìº í¼ìŠ¤ êµí•„ 1 2 2 0 ì›”7 ì›”8 2ê³µ4...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [ 0.00383119  0.11121961  0.02452121 -0.11931653 -0.07199366]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_SWAIá„‰á…¡á„‹á…¥á†¸á„ƒá…¡á†« 2022-á„ƒá…©á†¼á„€á…¨ á„‹á…µá†«á„á…¥á†«á„‰á…µá†¸ á„‘á…³á„…á…©á„€á…³á„…á…¢á†· á„‰á…µá†¯á„‰á…³á†¸á„‰á…¢á†¼ á„†á…©á„Œá…µá†¸ á„€á…©á†¼á„€á…©_chunk_0\n",
            "   ğŸ“ íŒŒì¼ëª…: SWAIá„‰á…¡á„‹á…¥á†¸á„ƒá…¡á†« 2022-á„ƒá…©á†¼á„€á…¨ á„‹á…µá†«á„á…¥á†«á„‰á…µá†¸ á„‘á…³á„…á…©á„€á…³á„…á…¢á†· á„‰á…µá†¯á„‰á…³á†¸á„‰á…¢á†¼ á„†á…©á„Œá…µá†¸ á„€á…©á†¼á„€á…©\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„’á…¡á†¨á„€á…ªá„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: markdown\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1423/263272/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: # SW/AIì‚¬ì—…ë‹¨ 2022-ë™ê³„ ì¸í„´ì‹­ í”„ë¡œê·¸ë¨ ì‹¤ìŠµìƒ ëª¨ì§‘ ê³µê³  **ì¶œì²˜:** [https://sw.kongju.ac.kr/bbs/ZD1180/1423/263272/artclView.do](https://sw.kongju.ac.kr/bbs/ZD1180/1423/263272/artclView.do) **ì‘ì„±ì:** ì„ì„±ì²  **ì‘ì„±ì¼:** 2022.11.2...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [-0.04881673  0.03529529  0.09625652  0.00971952 -0.0267488 ]\n",
            "----------------------------------------------------------------------\n",
            "ğŸ”¹ ID: Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)_2023 á„‰á…µá†«á„‹á…µá†¸á„‰á…¢á†¼ á„‹á…¡á†«á„‚á…¢á„€á…­á„‹á…²á†¨(OT) á„Œá…¡á„…á…­_chunk_2\n",
            "   ğŸ“ íŒŒì¼ëª…: 2023 á„‰á…µá†«á„‹á…µá†¸á„‰á…¢á†¼ á„‹á…¡á†«á„‚á…¢á„€á…­á„‹á…²á†¨(OT) á„Œá…¡á„…á…­\n",
            "   ğŸ« ë¶€ì„œ: Kongju National University Cheonan Campus (á„€á…©á†¼á„Œá…®á„ƒá…¢á„’á…¡á†¨á„€á…­ á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³)/Cheonan Campus Department (á„á…¥á†«á„‹á…¡á†«á„á…¢á†·á„‘á…¥á„‰á…³ á„’á…¡á†¨á„€á…ªá„‡á…§á†¯ á„‰á…¡á„‹á…µá„á…³)/Cheonan College of Engineering (á„á…¥á†«á„‹á…¡á†«á„€á…©á†¼á„€á…ªá„ƒá…¢á„’á…¡á†¨)/Software Department (á„‰á…©á„‘á…³á„á…³á„‹á…°á„‹á…¥á„’á…¡á†¨á„€á…ª)\n",
            "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: á„á…¥á„†á…²á„‚á…µá„á…µ (á„’á…¡á†¨á„€á…ªá„€á…©á†¼á„Œá…µ)\n",
            "   ğŸ“„ íƒ€ì…: pdf\n",
            "   ğŸŒ URL: https://sw.kongju.ac.kr/bbs/ZD1180/1423/269342/artclView.do\n",
            "   ğŸ“… ë‚ ì§œ: 2025-04-13\n",
            "   ğŸ’¬ ì²­í¬ ë¬¸ì¥: êµìœ¡ê³¼ì • -êµìœ¡ëª©í‘œë¥¼ë‹¬ì„±í•˜ê¸°ìœ„í•˜ì—¬ , ê·¸ë‚´ìš©ì„ì²´ê³„ì ìœ¼ë¡œ ì¡°ì§í•œêµìœ¡ê³„íšì˜ì „ì²´ â–ªìˆ˜ê°•ì‹ ì²­ -ê°•ì˜ë‚˜ì‹¤í—˜âˆ™ì‹¤ìŠµì„ë°›ê¸°ìœ„í•˜ì—¬ìì‹ ì´ì´ìˆ˜í• êµê³¼ëª©ì„ì„ íƒí•˜ì—¬ì‹ ì²­í•˜ëŠ”ê²ƒ 2. ìˆ˜ê°•ì‹ ì²­ ê´€ë ¨ìš©ì–´ì •ì˜3. êµìœ¡ê³¼ì •ì˜ êµ¬ì„± êµ¬ë¶„ í•™ì  ë¹„ê³  êµì–‘í•„ìˆ˜ê¸°ì´ˆêµì–‘í•„ìˆ˜ 8ê³µì£¼ëŒ€í•™êµ í•™ìƒë“¤ì´ê³µí†µìœ¼ë¡œìˆ˜ê°•í•´ì•¼í•˜ëŠ”êµì–‘ê³¼ëª© êµì–‘ì„ íƒê¸°ì´ˆêµì–‘ì„ íƒ 14ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ í•™ìƒë“¤ì´ìˆ˜ê°•í•´ì•¼êµì–‘ê³¼ëª© ê· í˜•êµì–‘ì„ íƒ 12ê³µê³¼...\n",
            "   ğŸ§  ë²¡í„° ê¸¸ì´: 384\n",
            "   ğŸ”¢ ë²¡í„° ì• 5ê°œ ê°’: [ 0.03407622  0.02518597  0.01949668 -0.04839326 -0.00861201]\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from chromadb import PersistentClient\n",
        "import unicodedata\n",
        "\n",
        "# 1. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
        "client = PersistentClient(path=\"/content/drive/MyDrive/chroma_index\")\n",
        "collection = client.get_collection(\"knu_cheonan_collection\")\n",
        "\n",
        "# 2. ëª¨ë“  ë¬¸ì„œ ë° ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ids í¬í•¨)\n",
        "all_data = collection.get(include=[\"documents\", \"metadatas\"])\n",
        "\n",
        "print(\"ğŸ” 'ì‹ ì…ìƒ' í¬í•¨ëœ file_name ê²€ìƒ‰ ì¤‘...\\n\")\n",
        "\n",
        "found = False\n",
        "\n",
        "# 3. ìˆœíšŒí•˜ë©´ì„œ 'ì‹ ì…ìƒ' í¬í•¨ ì—¬ë¶€ í™•ì¸\n",
        "for i, meta in enumerate(all_data[\"metadatas\"]):\n",
        "    file_name = meta.get(\"file_name\", \"\")\n",
        "    normalized_name = unicodedata.normalize(\"NFC\", file_name)\n",
        "\n",
        "    if \"ì‹ ì…ìƒ O.T\" in normalized_name:\n",
        "        found = True\n",
        "        print(f\"[{i+1}] âœ… ID: {all_data['ids'][i]}\")\n",
        "        print(f\"    ğŸ“„ file_name: {repr(file_name)}\")\n",
        "        print(f\"    ğŸ“ metadata: {meta}\")\n",
        "        print(f\"    ğŸ“ ë¬¸ì„œ ì¼ë¶€: {all_data['documents'][i][:80]}...\\n\")\n",
        "\n",
        "if not found:\n",
        "    print(\"âŒ 'ì‹ ì…ìƒ'ì´ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ file_name ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "i01w7CWKNS0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# ì¶œì²˜ URL ì—†ëŠ”ê±° ê²€ìƒ‰\n",
        "from chromadb import PersistentClient\n",
        "\n",
        "# âœ… 1. ChromaDB ì»¬ë ‰ì…˜ ì—´ê¸°\n",
        "client = PersistentClient(path=\"/content/drive/MyDrive/chroma_index\")\n",
        "collection = client.get_collection(name=\"knu_cheonan_collection\")\n",
        "\n",
        "# âœ… 2. ì „ì²´ ë¬¸ì„œ ì¡°íšŒ\n",
        "results = collection.get(limit=None, include=[\"documents\", \"metadatas\"])\n",
        "\n",
        "# âœ… 3. 'ì¶œì²˜ URL ì—†ìŒ' í•„í„°ë§\n",
        "no_url_chunks = []\n",
        "for id_, doc, meta in zip(results[\"ids\"], results[\"documents\"], results[\"metadatas\"]):\n",
        "    if meta.get(\"source_url\") == \"ì¶œì²˜ URL ì—†ìŒ\":\n",
        "        no_url_chunks.append((id_, doc, meta))\n",
        "\n",
        "# âœ… 4. ê²°ê³¼ ì¶œë ¥\n",
        "print(f\"\\nğŸ” 'ì¶œì²˜ URL ì—†ìŒ' ì²­í¬ ê°œìˆ˜: {len(no_url_chunks)}\")\n",
        "\n",
        "for id_, doc, meta in no_url_chunks:\n",
        "    print(\"\\nğŸ†” ID:\", id_)\n",
        "    print(\"ğŸ“ ì²­í¬ ë‚´ìš©:\")\n",
        "    print(doc)\n",
        "    print(\"ğŸ“ ë©”íƒ€ë°ì´í„°:\")\n",
        "    print(meta)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Miha3PQUDXFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì™„ì „ ë‚´ë¶€ ì´ˆê¸°í™” ------ ì‹ ì¤‘íˆ ì‚¬ìš©í•˜ê¸° ë°”ëŒ -------\n",
        "\"\"\"\n",
        "from chromadb import PersistentClient\n",
        "\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/chroma_index\"\n",
        "COLLECTION_NAME = \"knu_cheonan_collection\"\n",
        "\n",
        "client = PersistentClient(path=PERSIST_DIR)\n",
        "collection = client.get_or_create_collection(name=COLLECTION_NAME)\n",
        "\n",
        "# ì»¬ë ‰ì…˜ ë‚´ì˜ ëª¨ë“  ë¬¸ì„œ IDë¥¼ ê°€ì ¸ì™€ ì‚­ì œ\n",
        "existing_ids = collection.get(limit=None)['ids']\n",
        "if existing_ids:\n",
        "    collection.delete(ids=existing_ids)\n",
        "    print(f\"ğŸ—‘ï¸ ì»¬ë ‰ì…˜ ë‚´ ëª¨ë“  ë°ì´í„° ì‚­ì œ ì™„ë£Œ: {len(existing_ids)}ê°œ ì‚­ì œë¨\")\n",
        "else:\n",
        "    print(\"âœ… ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "z8uhQAFgwRdd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# ì»¬ë ‰ì…˜ Drop\n",
        "from chromadb import PersistentClient\n",
        "\n",
        "PERSIST_DIR = \"/content/drive/MyDrive/chroma_index\"\n",
        "COLLECTION_NAME = \"knu_cheonan_collection\"\n",
        "\n",
        "client = PersistentClient(path=PERSIST_DIR)\n",
        "\n",
        "# ì»¬ë ‰ì…˜ ì‚­ì œ\n",
        "client.delete_collection(name=COLLECTION_NAME)\n",
        "print(f\"ğŸ—‘ï¸ ì»¬ë ‰ì…˜ '{COLLECTION_NAME}' ì‚­ì œ ì™„ë£Œ\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Rtb_DL890ylq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ëŠ¥ ë¹„êµ => PyPDF2ê°€ ë” ì˜ ë‚˜ì˜´\n",
        "!pip install PyPDF2\n",
        "!pip install pdfplumber\n",
        "\n",
        "import PyPDF2\n",
        "import pdfplumber\n",
        "\n",
        "with open(\"/content/drive/MyDrive/document_files/Department (í•™ë¶€)/Cheonan College of Engineering (ì²œì•ˆê³µê³¼ëŒ€í•™)/Software Department (ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼)/ì»¤ë®¤ë‹ˆí‹°(ê·œì •ìë£Œì‹¤)/ë¯¸ë˜ì„¤ê³„ êµê³¼ëª© ì´ìˆ˜ê¸°ì¤€(2021.04.19.).pdf\", \"rb\") as f:\n",
        "    reader = PyPDF2.PdfReader(f)\n",
        "    print(\"[PyPDF2]\")\n",
        "    print(reader.pages[0].extract_text())\n",
        "\n",
        "with pdfplumber.open(\"/content/drive/MyDrive/document_files/Department (í•™ë¶€)/Cheonan College of Engineering (ì²œì•ˆê³µê³¼ëŒ€í•™)/Software Department (ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼)/ì»¤ë®¤ë‹ˆí‹°(ê·œì •ìë£Œì‹¤)/ë¯¸ë˜ì„¤ê³„ êµê³¼ëª© ì´ìˆ˜ê¸°ì¤€(2021.04.19.).pdf\") as pdf:\n",
        "    print(\"\\n[pdfplumber]\")\n",
        "    print(pdf.pages[0].extract_text())\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EYw4poMgwzUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" ì˜ˆì œ ì½”ë“œì—ì„œ ì‚¬ìš©í•  OCR ì„¤ì¹˜\n",
        "# Tesseract OCR => ì¶”ì¶œì´ ì´ìƒí•˜ê²Œ ë¨\n",
        "!apt-get install -y poppler-utils\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install pytesseract pdf2image Pillow\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" ì´ê±° ì‚¬ìš©í•¨\n",
        "# PaddleOCR ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ) => í•œê¸€ ì§€ì› ë§¤ìš° ì¢‹ê³ , ì •í™•ë„ë„ ë†’ìŒ, ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê³ ì •ë°€ OCR\n",
        "!pip install paddleocr\n",
        "!pip install \"paddlepaddle==2.6.2\" -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
        "!apt-get install -y poppler-utils\n",
        "!pip install pdf2image\n",
        "!pip install matplotlib\n",
        "\"\"\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "iJ-_yVBdZecg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "# ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "IMG_PATH = \"/content/drive/MyDrive/sample/ê³µê²°ê·œì •_ì‚¬ë³¸.jpg\"\n",
        "\n",
        "# ì´ë¯¸ì§€ ë¡œë“œ (ì „ì²˜ë¦¬ ì—†ìŒ)\n",
        "img = Image.open(IMG_PATH)\n",
        "\n",
        "# OCR ìˆ˜í–‰\n",
        "text = pytesseract.image_to_string(img, lang=\"kor+eng\", config=\"--psm 6 --oem 3\")\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"ğŸ–¼ï¸ ì´ë¯¸ì§€ OCR ì¶”ì¶œ ê²°ê³¼:\\n\")\n",
        "print(text)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tDEsQAsIVIoY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# ì„¤ì •\n",
        "POPPLER_PATH = \"/usr/bin\"\n",
        "PDF_PATH = \"/content/drive/MyDrive/sample/2. í™ë³´ìë£Œ_ICT ìœµí•©ì¸ì¬ ì–‘ì„±ê³¼ì •.pdf\"\n",
        "LANG = \"kor+eng\"\n",
        "\n",
        "# PDF â†’ ì´ë¯¸ì§€ ë³€í™˜\n",
        "images = convert_from_path(PDF_PATH, dpi=300, poppler_path=POPPLER_PATH)\n",
        "\n",
        "# OCR ì‹¤í–‰, ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì—†ì–´ ê¸°ë³¸ ëª¨ë¸ ì„±ëŠ¥ë§Œìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "for i, page in enumerate(images):\n",
        "    text = pytesseract.image_to_string(page, lang=LANG)\n",
        "    print(f\"\\n--- Page {i+1} ---\")\n",
        "    print(text)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SkVvFS7tVANY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from paddleocr import PaddleOCR\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# OCR ì´ˆê¸°í™” (í•œê¸€ ì§€ì›)\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='korean')\n",
        "\n",
        "# ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "IMG_PATH = \"/content/drive/MyDrive/sample/ê³µê²°ê·œì •_ì‚¬ë³¸.jpg\"\n",
        "\n",
        "# ì´ë¯¸ì§€ ë¡œë“œ (ì „ì²˜ë¦¬ ì—†ìŒ)\n",
        "img = Image.open(IMG_PATH)\n",
        "image_np = np.array(img.convert(\"RGB\"))[:, :, ::-1]  # PIL â†’ NumPy(BGR)\n",
        "\n",
        "# OCR ìˆ˜í–‰\n",
        "result = ocr.ocr(image_np, cls=True)\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"ğŸ–¼ï¸ ì´ë¯¸ì§€ OCR ì¶”ì¶œ ê²°ê³¼:\\n\")\n",
        "for line in result[0]:\n",
        "    text = line[1][0]\n",
        "    print(text)\n",
        "\"\"\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "6CmuGaIqiiBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from paddleocr import PaddleOCR\n",
        "from pdf2image import convert_from_path\n",
        "import numpy as np\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì •\n",
        "POPPLER_PATH = \"/usr/bin\"\n",
        "PDF_PATH = \"/content/drive/MyDrive/sample/2. í™ë³´ìë£Œ_ICT ìœµí•©ì¸ì¬ ì–‘ì„±ê³¼ì •.pdf\"\n",
        "\n",
        "# OCR ì´ˆê¸°í™” (í•œê¸€ ì§€ì›)\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='korean')\n",
        "\n",
        "# PDF â†’ ì´ë¯¸ì§€ ë³€í™˜\n",
        "images = convert_from_path(PDF_PATH, dpi=300, poppler_path=POPPLER_PATH)\n",
        "\n",
        "# OCR ì‹¤í–‰, ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì—†ì–´ ê¸°ë³¸ ëª¨ë¸ ì„±ëŠ¥ë§Œìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "full_text = \"\"\n",
        "for i, page in enumerate(images):\n",
        "    image_np = np.array(page)[:, :, ::-1]  # PIL â†’ numpy (BGR)\n",
        "\n",
        "    result = ocr.ocr(image_np, cls=True)\n",
        "\n",
        "    full_text += f\"\\n--- Page {i+1} ---\\n\"\n",
        "    for line in result[0]:\n",
        "        full_text += line[1][0] + \"\\n\"\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"ğŸ“„ ì „ì²´ OCR í…ìŠ¤íŠ¸ ê²°ê³¼:\\n\")\n",
        "print(full_text)\n",
        "\"\"\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "klIARJL-ayNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# ì—‘ì…€íŒŒì¼ -> í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "!pip install openpyxl\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# âœ… íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì…ë ¥í•œ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
        "PDF_PATH = \"/content/drive/MyDrive/sample/Software Department (ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼).xlsx\"\n",
        "\n",
        "def extract_text_from_excel(file_path):\n",
        "    try:\n",
        "        xls = pd.read_excel(file_path, sheet_name=None, dtype=str)\n",
        "        all_text = \"\"\n",
        "\n",
        "        for sheet_name, df in xls.items():\n",
        "            df = df.fillna(\"\")\n",
        "            sheet_text = \"\\n\".join([\"\\t\".join(row) for row in df.values.tolist()])\n",
        "            all_text += f\"\\n=== ì‹œíŠ¸: {sheet_name} ===\\n{sheet_text}\\n\"\n",
        "\n",
        "        return all_text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {file_path} ({e})\")\n",
        "        return \"\"\n",
        "\n",
        "# âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤í–‰\n",
        "extracted_text = extract_text_from_excel(PDF_PATH)\n",
        "\n",
        "if extracted_text:\n",
        "    print(\"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ (ì•ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°):\\n\")\n",
        "    print(extracted_text[:3000])  # ë„ˆë¬´ ê¸¸ ê²½ìš° ì•ë¶€ë¶„ë§Œ ë¯¸ë¦¬ë³´ê¸°\n",
        "else:\n",
        "    print(\"âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë‚´ìš© ì—†ìŒ.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "YlrEKAw9nV4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}