{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtfFwh1FVuAEIDbXJ4Awx+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KNUckle-llm/experiments/blob/main/Q%26A_ChatBot2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N6M_z_4XXs1"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°(openai API í‚¤)\n",
        "load_dotenv('/content/drive/MyDrive/Colab Notebooks/.env')\n",
        "\n",
        "# LLM ì„¤ì •\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ë¶„ë¦¬\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "message = \"\"\"\n",
        "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
        "ë‹¹ì‹ ì˜ ì…ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥ì„ í† ëŒ€ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
        "ë§Œì•½, ë¬¸ë§¥ì—ì„œ ë‹µë³€ì„ ìœ„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ 'ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' ë¼ê³  ë‹µí•˜ì„¸ìš”.\n",
        "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´ í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
        "\n",
        "## ì£¼ì–´ì§„ ë¬¸ë§¥:\n",
        "{context}\n",
        "\n",
        "## ì‚¬ìš©ì ì§ˆë¬¸:\n",
        "{input}\n",
        "\"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", message)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ì¶œë ¥ íŒŒì„œ\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# ì „ì—­ ë³€ìˆ˜\n",
        "db = None\n",
        "retriever = None\n",
        "rag_chain = None\n",
        "\n",
        "def load_pdf(file):\n",
        "  global db, retriever, rag_chain\n",
        "\n",
        "  # ì €ì¥ëœ íŒŒì¼ë¡œ ë¡œë“œ\n",
        "  loader = PyPDFLoader(file.name)\n",
        "  docs = loader.load_and_split(text_splitter=text_splitter)\n",
        "\n",
        "  db = FAISS.from_documents(docs, hf_embeddings)\n",
        "  retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "  rag_chain = {\n",
        "      \"context\": retriever,\n",
        "      \"input\": RunnablePassthrough()\n",
        "  } | prompt_template | llm | parser\n",
        "\n",
        "  return \"PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œ ë° ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.\"\n",
        "\n",
        "def answer_question(question):\n",
        "  if rag_chain is None:\n",
        "    return \"ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”!\"\n",
        "  return rag_chain.invoke(question)\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "  gr.Markdown(\"\"\"\n",
        "  # ğŸ“„ ì¸ê³µì§€ëŠ¥ PDF Q&A ì±—ë´‡\n",
        "  **PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤!**\n",
        "\"\"\")\n",
        "\n",
        "  with gr.Row():\n",
        "    with gr.Column(scale=1):\n",
        "      file_input = gr.File(label=\"PDF íŒŒì¼ ì—…ë¡œë“œ\")\n",
        "      upload_button = gr.Button(\"ğŸ“¤ ì—…ë¡œë“œ ë° ì²˜ë¦¬\")\n",
        "\n",
        "    with gr.Column(scale=2):\n",
        "      status_output = gr.Textbox(label=\"ğŸ“¢ ìƒíƒœ ë©”ì‹œì§€\")\n",
        "      question_input = gr.Textbox(label=\"â“ ì§ˆë¬¸ ì…ë ¥\", placeholder=\"ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì ì–´ì£¼ì„¸ìš”.\")\n",
        "      submit_button = gr.Button(\"ğŸ¤– ë‹µë³€ ë°›ê¸°\")\n",
        "      answer_output = gr.Textbox(label=\"ğŸ“ AI ë‹µë³€\")\n",
        "\n",
        "  upload_button.click(load_pdf, inputs=file_input, outputs=status_output)\n",
        "  submit_button.click(answer_question, inputs=question_input, outputs=answer_output)\n",
        "\n",
        "demo.launch() # ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"
      ]
    }
  ]
}